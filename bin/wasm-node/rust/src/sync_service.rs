// Substrate-lite
// Copyright (C) 2019-2020  Parity Technologies (UK) Ltd.
// SPDX-License-Identifier: GPL-3.0-or-later WITH Classpath-exception-2.0

// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.

// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.

// You should have received a copy of the GNU General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.

use futures::{
    channel::{mpsc, oneshot},
    lock::Mutex,
    prelude::*,
};
use std::{collections::HashMap, num::NonZeroU32, pin::Pin};
use substrate_lite::{chain, chain::sync::headers_optimistic, network};

/// Configuration for a [`SyncService`].
pub struct Config {
    /// State of the finalized chain.
    pub chain_information: chain::chain_information::ChainInformation,

    /// Closure that spawns background tasks.
    pub tasks_executor: Box<dyn FnMut(Pin<Box<dyn Future<Output = ()> + Send>>) + Send>,
}

/// Event generated by [`SyncService::next_event`].
#[derive(Debug)]
pub enum Event {
    BlocksRequest {
        id: BlocksRequestId,
        target: network::PeerId,
        request: network::protocol::BlocksRequestConfig,
    },
    /// Current best block has been updated.
    NewBest {
        /// Header of the new best block, in SCALE encoding.
        scale_encoded_header: Vec<u8>,
    },
}

/// Identifier for a blocks request to be performed.
#[derive(Debug, Copy, Clone, Ord, PartialOrd, Eq, PartialEq, Hash)]
pub struct BlocksRequestId(usize);

pub struct SyncService {
    /// Sender of messages towards the background task.
    to_background: Mutex<mpsc::Sender<ToBackground>>,

    /// Receiver of events sent by the background task.
    from_background: Mutex<mpsc::Receiver<FromBackground>>,

    /// For each emitted blocks request, an element is stored here.
    blocks_requests:
        Mutex<slab::Slab<oneshot::Sender<Result<Vec<network::protocol::BlockData>, ()>>>>,
}

impl SyncService {
    pub async fn new(mut config: Config) -> Self {
        let (to_foreground, from_background) = mpsc::channel(16);
        let (to_background, from_foreground) = mpsc::channel(16);

        (config.tasks_executor)(Box::pin(
            start_sync(config.chain_information, from_foreground, to_foreground).await,
        ));

        SyncService {
            to_background: Mutex::new(to_background),
            from_background: Mutex::new(from_background),
            blocks_requests: Mutex::new(slab::Slab::new()),
        }
    }

    /// Registers a new source for blocks.
    pub async fn add_source(&self, peer_id: network::PeerId) {
        self.to_background
            .lock()
            .await
            .send(ToBackground::PeerConnected(peer_id))
            .await
            .unwrap()
    }

    /// Removes a source of blocks.
    pub async fn remove_source(&self, peer_id: network::PeerId) {
        self.to_background
            .lock()
            .await
            .send(ToBackground::PeerDisconnected(peer_id))
            .await
            .unwrap()
    }

    /// Sets the answer to a previously-emitted [`Event::BlocksRequest`].
    ///
    /// After this has been called, the `id` is no longer valid.
    ///
    /// # Panic
    ///
    /// Panics if the `id` is invalid.
    ///
    pub async fn answer_blocks_request(
        &self,
        id: BlocksRequestId,
        response: Result<Vec<network::protocol::BlockData>, ()>,
    ) {
        let _ = self
            .blocks_requests
            .lock()
            .await
            .remove(id.0)
            .send(response);
    }

    /// Returns the next event that happened in the sync service.
    ///
    /// If this method is called multiple times simultaneously, the events will be distributed
    /// amongst the different calls in an unpredictable way.
    pub async fn next_event(&self) -> Event {
        loop {
            match self.from_background.lock().await.next().await.unwrap() {
                FromBackground::RequestStart {
                    target,
                    request,
                    send_back,
                } => {
                    let id = BlocksRequestId(self.blocks_requests.lock().await.insert(send_back));
                    return Event::BlocksRequest {
                        id,
                        target,
                        request,
                    };
                }
                FromBackground::NewBest {
                    scale_encoded_header,
                } => {
                    return Event::NewBest {
                        scale_encoded_header,
                    };
                }
            }
        }
    }
}

async fn start_sync(
    chain_information: chain::chain_information::ChainInformation,
    mut from_foreground: mpsc::Receiver<ToBackground>,
    mut to_foreground: mpsc::Sender<FromBackground>,
) -> impl Future<Output = ()> {
    let mut sync = headers_optimistic::OptimisticHeadersSync::<_, network::PeerId>::new(
        headers_optimistic::Config {
            chain_information,
            sources_capacity: 32,
            source_selection_randomness_seed: rand::random(),
            blocks_request_granularity: NonZeroU32::new(128).unwrap(),
            download_ahead_blocks: {
                // Assuming a verification speed of 1k blocks/sec and a 95% latency of one second,
                // the number of blocks to download ahead of time in order to not block is 1000.
                1024
            },
        },
    );

    async move {
        let mut peers_source_id_map = HashMap::new();
        let mut block_requests_finished = stream::FuturesUnordered::new();

        loop {
            while let Some(action) = sync.next_request_action() {
                match action {
                    headers_optimistic::RequestAction::Start {
                        start,
                        block_height,
                        source,
                        num_blocks,
                        ..
                    } => {
                        let (send_back, rx) = oneshot::channel();

                        let send_result = to_foreground
                            .send(FromBackground::RequestStart {
                                target: source.clone(),
                                request: network::protocol::BlocksRequestConfig {
                                    start: network::protocol::BlocksRequestConfigStart::Number(
                                        block_height,
                                    ),
                                    desired_count: num_blocks,
                                    direction: network::protocol::BlocksRequestDirection::Ascending,
                                    fields: network::protocol::BlocksRequestFields {
                                        header: true,
                                        body: false,
                                        justification: true,
                                    },
                                },
                                send_back,
                            })
                            .await;

                        // If the channel is closed, the sync service has been closed too.
                        if send_result.is_err() {
                            return;
                        }

                        let (rx, abort) = future::abortable(rx);
                        let request_id = start.start(abort);
                        block_requests_finished.push(rx.map(move |r| (request_id, r)));
                    }
                    headers_optimistic::RequestAction::Cancel { user_data, .. } => {
                        user_data.abort();
                    }
                }
            }

            // Verify blocks that have been fetched from queries.
            loop {
                match sync.process_one(crate::ffi::unix_time()) {
                    headers_optimistic::ProcessOneOutcome::Idle => break,
                    headers_optimistic::ProcessOneOutcome::Updated { new_best_block, .. }
                    | headers_optimistic::ProcessOneOutcome::Reset { new_best_block, .. } => {
                        if to_foreground
                            .send(FromBackground::NewBest {
                                scale_encoded_header: new_best_block.scale_encoding().fold(
                                    Vec::new(),
                                    |mut a, b| {
                                        a.extend_from_slice(b.as_ref());
                                        a
                                    },
                                ),
                            })
                            .await
                            .is_err()
                        {
                            return;
                        }
                    }
                }

                // Since `process_one` is a CPU-heavy operation, looping until it is done can
                // take a long time. In order to avoid blocking the rest of the program in the
                // meanwhile, the `yield_once` function interrupts the current task and gives a
                // chance for other tasks to progress.
                crate::yield_once().await;
            }

            futures::select! {
                message = from_foreground.next() => {
                    let message = match message {
                        Some(m) => m,
                        None => {
                            return
                        },
                    };

                    match message {
                        ToBackground::PeerConnected(peer_id) => {
                            let id = sync.add_source(peer_id.clone());
                            peers_source_id_map.insert(peer_id.clone(), id);
                        },
                        ToBackground::PeerDisconnected(peer_id) => {
                            let id = peers_source_id_map.remove(&peer_id).unwrap();
                            let (_, rq_list) = sync.remove_source(id);
                            for (_, rq) in rq_list {
                                rq.abort();
                            }
                        },
                    }
                },

                (request_id, result) = block_requests_finished.select_next_some() => {
                    // `result` is an error if the block request got cancelled by the sync state
                    // machine.
                    if let Ok(result) = result {
                        let result = result.map_err(|_| ()).and_then(|v| v);
                        let _ = sync.finish_request(request_id, result.map(|v| v.into_iter().map(|block| headers_optimistic::RequestSuccessBlock {
                            scale_encoded_header: block.header.unwrap(), // TODO: don't unwrap
                            scale_encoded_justification: block.justification,
                        })).map_err(|()| headers_optimistic::RequestFail::BlocksUnavailable));
                    }
                },
            }
        }
    }
}

enum ToBackground {
    PeerConnected(network::PeerId),
    PeerDisconnected(network::PeerId),
}

/// Messsage sent from the background task and dedicated to the main [`SyncService`]. Processed
/// in [`SyncService::next_event`].
enum FromBackground {
    /// A blocks request must be started.
    RequestStart {
        target: network::PeerId,
        request: network::protocol::BlocksRequestConfig,
        send_back: oneshot::Sender<Result<Vec<network::protocol::BlockData>, ()>>, // TODO: proper error
    },
    /// Current best block has been updated.
    NewBest {
        /// Header of the new best block, in SCALE encoding.
        scale_encoded_header: Vec<u8>,
    },
}
