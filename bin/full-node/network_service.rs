// Substrate-lite
// Copyright (C) 2019-2020  Parity Technologies (UK) Ltd.
// SPDX-License-Identifier: GPL-3.0-or-later WITH Classpath-exception-2.0

// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.

// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.

// You should have received a copy of the GNU General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.

//! Background network service.
//!
//! The [`NetworkService`] manages background tasks dedicated to connecting to other nodes.
//! Importantly, its design is oriented towards the particular use case of the full node.
//!
//! The [`NetworkService`] spawns one background task (using the [`Config::tasks_executor`]) for
//! each active TCP socket, plus one for each TCP listening socket. Messages are exchanged between
//! the service and these background tasks.

// TODO: doc
// TODO: re-review this once finished

use core::{iter, pin::Pin, time::Duration};
use futures::{
    channel::{mpsc, oneshot},
    lock::{Mutex, MutexGuard},
    prelude::*,
};
use std::{io, net::SocketAddr, sync::Arc, time::Instant};
use substrate_lite::network::{
    connection,
    multiaddr::{Multiaddr, Protocol},
    peer_id::PeerId,
    peerset, protocol, service, with_buffers,
};

/// Configuration for a [`NetworkService`].
pub struct Config {
    /// Closure that spawns background tasks.
    pub tasks_executor: Box<dyn FnMut(Pin<Box<dyn Future<Output = ()> + Send>>) + Send>,

    /// Addresses to listen for incoming connections.
    pub listen_addresses: Vec<Multiaddr>,

    /// List of node identities and addresses that are known to belong to the chain's peer-to-pee
    /// network.
    pub bootstrap_nodes: Vec<(PeerId, Multiaddr)>,

    /// Hash of the genesis block of the chain. Sent to other nodes in order to determine whether
    /// the chains match.
    pub genesis_block_hash: [u8; 32],

    /// Number and hash of the current best block. Can later be updated with // TODO: which function?
    pub best_block: (u64, [u8; 32]),

    /// Identifier of the chain to connect to.
    ///
    /// Each blockchain has (or should have) a different "protocol id". This value identifies the
    /// chain, so as to not introduce conflicts in the networking messages.
    pub protocol_id: String,

    /// Key used for the encryption layer.
    /// This is a Noise static key, according to the Noise specifications.
    /// Signed using the actual libp2p key.
    pub noise_key: connection::NoiseKey,
}

/// Event generated by [`NetworkService::next_event`].
#[derive(Debug)]
pub enum Event {
    Connected(PeerId),
    Disconnected(PeerId),
}

pub struct NetworkService {
    /// Fields behind a mutex.
    guarded: Mutex<Guarded>,

    /// Receiver of events sent by background tasks.
    ///
    /// > **Note**: This field is not in [`Guarded`] despite being inside of a mutex. The mutex
    /// >           around this receiver is kept locked while an event is being waited for, and it
    /// >           would be undesirable to block access to the other fields of [`Guarded`] during
    /// >           that time.
    from_background: Mutex<mpsc::Receiver<FromBackground>>,

    /// Sending side of [`NetworkService::from_background`]. Clones of this field are created when
    /// a background task is spawned.
    to_foreground: mpsc::Sender<FromBackground>,
}

/// Fields of [`NetworkService`] behind a mutex.
struct Guarded {
    /// See [`Config::tasks_executor`].
    tasks_executor: Box<dyn FnMut(Pin<Box<dyn Future<Output = ()> + Send>>) + Send>,

    /// Data structure holding the entire state of the networking.
    network: service::Network<()>,
}

impl NetworkService {
    /// Initializes the network service with the given configuration.
    pub async fn new(mut config: Config) -> Result<Arc<Self>, InitError> {
        // Channel used for the background to communicate to the foreground.
        // Once this channel is full, background tasks that need to send a message to the network
        // service will block and wait for some space to be available.
        //
        // The ideal size of this channel depends on the volume of messages, the time it takes for
        // the network service to be polled after being waken up, and the speed of messages
        // processing. All these components are pretty hard to know in advance, and as such we go
        // for the approach of choosing an arbitrary constant value.
        let (to_foreground, from_background) = mpsc::channel(256);

        // For each listening address in the configuration, create a background task dedicated to
        // listening on that address.
        for listen_address in config.listen_addresses {
            // Try to parse the requested address and create the corresponding listening socket.
            let tcp_listener: async_std::net::TcpListener = {
                let mut iter = listen_address.iter();
                let proto1 = match iter.next() {
                    Some(p) => p,
                    None => return Err(InitError::BadListenMultiaddr(listen_address)),
                };
                let proto2 = match iter.next() {
                    Some(p) => p,
                    None => return Err(InitError::BadListenMultiaddr(listen_address)),
                };

                if iter.next().is_some() {
                    return Err(InitError::BadListenMultiaddr(listen_address));
                }

                let addr = match (proto1, proto2) {
                    (Protocol::Ip4(ip), Protocol::Tcp(port)) => SocketAddr::from((ip, port)),
                    (Protocol::Ip6(ip), Protocol::Tcp(port)) => SocketAddr::from((ip, port)),
                    _ => return Err(InitError::BadListenMultiaddr(listen_address)),
                };

                match async_std::net::TcpListener::bind(addr).await {
                    Ok(l) => l,
                    Err(err) => {
                        return Err(InitError::ListenerIo(listen_address, err));
                    }
                }
            };

            // Spawn a background task dedicated to this listener.
            let mut to_foreground = to_foreground.clone();
            (config.tasks_executor)(Box::pin(async move {
                loop {
                    // TODO: add a way to immediately interrupt the listener if the network service is destroyed (or fails to create altogether), in order to immediately liberate the port

                    let (socket, _addr) = match tcp_listener.accept().await {
                        Ok(v) => v,
                        Err(_) => {
                            // Errors here can happen if the accept failed, for example if no file
                            // descriptor is available.
                            // A wait is added in order to avoid having a busy-loop failing to
                            // accept connections.
                            futures_timer::Delay::new(Duration::from_secs(2)).await;
                            continue;
                        }
                    };

                    if to_foreground
                        .send(FromBackground::NewConnection {
                            socket,
                            is_initiator: false,
                        })
                        .await
                        .is_err()
                    {
                        break;
                    }
                }
            }))
        }

        Ok(Arc::new(NetworkService {
            guarded: Mutex::new(Guarded {
                tasks_executor: config.tasks_executor,
                peerset,
            }),
            genesis_block_hash: config.genesis_block_hash,
            best_block: config.best_block,
            protocol_id: config.protocol_id,
            noise_key: Arc::new(config.noise_key),
            from_background: Mutex::new(from_background),
            to_foreground,
        }))
    }

    /// Returns the number of established TCP connections, both incoming and outgoing.
    pub async fn num_established_connections(&self) -> usize {
        self.guarded
            .lock()
            .await
            .peerset
            .num_established_connections()
    }

    /// Sends a blocks request to the given peer.
    // TODO: more docs
    // TODO: proper error type
    pub async fn blocks_request(
        self: Arc<Self>,
        target: PeerId,
        config: protocol::BlocksRequestConfig,
    ) -> Result<Vec<protocol::BlockData>, ()> {
        let mut guarded = self.guarded.lock().await;

        let connection = match guarded.peerset.node_mut(target) {
            peerset::NodeMut::Known(n) => n.connections().next().ok_or(())?,
            peerset::NodeMut::Unknown(n) => return Err(()),
        };

        let (send_back, receive_result) = oneshot::channel();

        let protocol = format!("/{}/sync/2", self.protocol_id);

        // TODO: is awaiting here a good idea? if the background task is stuck, we block the entire `Guarded`
        // It is possible for the channel to be closed, if the background task has ended but the
        // frontend hasn't processed this yet.
        guarded
            .peerset
            .connection_mut(connection)
            .unwrap()
            .into_user_data()
            .send(service::ServiceToConnection::BlocksRequest {
                config,
                protocol,
                send_back,
            })
            .await
            .map_err(|_| ())?;

        // Everything must be unlocked at this point.
        drop(guarded);

        // Wait for the result of the request. Can take a long time (i.e. several seconds).
        match receive_result.await {
            Ok(r) => r,
            Err(_) => Err(()),
        }
    }

    /// Returns the next event that happens in the network service.
    ///
    /// If this method is called multiple times simultaneously, the events will be distributed
    /// amongst the different calls in an unpredictable way.
    pub async fn next_event(&self) -> Event {
        let mut from_background = self.from_background.lock().await;

        loop {
            let message = from_background.next().await.unwrap();

            // Note that `from_background` is kept locked while `guarded` is locked, in order to
            // avoid an accidental reordering of the events coming from `from_background` if
            // `next_event` is called multiple times simultaneously.
            let mut guarded = self.guarded.lock().await;

            match message {
                FromBackground::NewConnection {
                    socket,
                    is_initiator,
                } => {
                    // A new socket has been accepted by a listener.
                    // Add the socket to the local state, and spawn the task of that connection.
                    /*let (tx, rx) = mpsc::channel(8);
                    guarded.network.add_incoming_connection(local_listen_address, remote_addr, user_data);
                    (guarded.tasks_executor)(Box::pin(connection_task(
                        future::ok(socket),
                        is_initiator,
                        self.noise_key.clone(),
                        connection_id,
                        self.to_foreground.clone(),
                        rx,
                    )));*/
                    // TODO: there's nothing in place for pending incoming at the moment
                    todo!()
                }
                FromBackground::ConnectionToService(message) => {
                    guarded.network.connection_message(message)
                }
            }
        }
    }
}

/// Error when initializing the network service.
#[derive(Debug, derive_more::Display)]
pub enum InitError {
    /// I/O error when initializing a listener.
    #[display(fmt = "I/O error when creating listener for {}: {}", _0, _1)]
    ListenerIo(Multiaddr, io::Error),
    /// A listening address passed through the configuration isn't valid.
    BadListenMultiaddr(Multiaddr),
}

/// Messsage sent from a background task and dedicated to the main [`NetworkService`]. Processed
/// in [`NetworkService::next_event`].
enum FromBackground {
    /// A new socket has arrived on a listening endpoint, or we have reached a remote.
    NewConnection {
        socket: async_std::net::TcpStream,
        is_initiator: bool,
    },

    ConnectionToService(service::ConnectionToService),
}

/// Asynchronous task managing a specific TCP connection.
async fn connection_task(
    tcp_socket: impl Future<Output = Result<async_std::net::TcpStream, io::Error>>,
    connection: service::Connection<Instant, (), (), (), (), ()>,
    mut to_foreground: mpsc::Sender<FromBackground>,
    mut to_connection: mpsc::Receiver<service::ServiceToConnection>,
) {
    // Finishing any ongoing connection process.
    let tcp_socket = match tcp_socket.await {
        Ok(s) => s,
        Err(_) => {
            let _ = to_foreground
                .send(FromBackground::HandshakeError {
                    connection_id,
                    error: HandshakeError::Io,
                })
                .await;
            return;
        }
    };

    // The Nagle algorithm, implemented in the kernel, consists in buffering the data to be sent
    // out and waiting a bit before actually sending it out, in order to potentially merge
    // multiple writes in a row into one packet. In the implementation below, it is guaranteed
    // that the buffer in `WithBuffers` is filled with as much data as possible before the
    // operating system gets involved. As such, we disable the Nagle algorithm, in order to avoid
    // adding an artificial delay to all sends.
    let _ = tcp_socket.set_nodelay(true);

    // The socket is wrapped around a `WithBuffers` object containing a read buffer and a write
    // buffer. These are the buffers whose pointer is passed to `read(2)` and `write(2)` when
    // reading/writing the socket.
    let tcp_socket = with_buffers::WithBuffers::new(tcp_socket);
    futures::pin_mut!(tcp_socket);

    // Notify the outside of the transition from handshake to actual connection, and obtain an
    // updated `connection_id` in return.
    // It is possible for the outside to refuse the connection after the handshake (if e.g. the
    // `PeerId` isn't the one that is expected), in which case the task stops entirely.
    let connection_id = {
        let (accept_tx, accept_rx) = oneshot::channel();

        if to_foreground
            .send(FromBackground::HandshakeSuccess {
                connection_id,
                peer_id,
                accept_tx,
            })
            .await
            .is_err()
        {
            return;
        }

        match accept_rx.await {
            Ok(id) => id,
            Err(_) => return,
        }
    };

    // Set to a timer after which the state machine of the connection needs an update.
    let mut poll_after: futures_timer::Delay;

    loop {
        let (read_buffer, write_buffer) = match tcp_socket.buffers() {
            Ok(b) => b,
            Err(_) => {
                let _ = to_foreground
                    .send(FromBackground::Disconnected { connection_id })
                    .await;
                return;
            }
        };

        let now = Instant::now();

        let read_write =
            match connection.read_write(now, read_buffer.map(|b| b.0), write_buffer.unwrap()) {
                Ok(rw) => rw,
                Err(_) => {
                    let _ = to_foreground
                        .send(FromBackground::Disconnected { connection_id })
                        .await;
                    return;
                }
            };
        connection = read_write.connection;

        if let Some(wake_up) = read_write.wake_up_after {
            if wake_up > now {
                let dur = wake_up - now;
                poll_after = futures_timer::Delay::new(dur);
            } else {
                poll_after = futures_timer::Delay::new(Duration::from_secs(0));
            }
        } else {
            poll_after = futures_timer::Delay::new(Duration::from_secs(3600));
        }

        tcp_socket.advance(read_write.read_bytes, read_write.written_bytes);

        let has_message = read_write.message.is_some();

        if let Some(message) = read_write.message {
            if to_foreground.send(message).await.is_err() {
                // Channel is closed. Nothing more can be done.
                return;
            }
        }

        // TDOO: clean shut down of TCP connection
        if read_write.ended {
            return;
        }

        if has_message || read_write.read_bytes != 0 || read_write.written_bytes != 0 {
            continue;
        }
    
        // TODO: maybe optimize the code below so that multiple messages are pulled from `to_connection` at once

        futures::select! {
            _ = tcp_socket.as_mut().process().fuse() => {},
            timeout = (&mut poll_after).fuse() => { // TODO: no, ref mut + fuse() = probably panic
                // Nothing to do, but guarantees that we loop again.
            },
            message = to_connection.select_next_some().fuse() => {
                connection.service_message(message);
            }
        }
    }
}

/// Builds a future that connects to the given multiaddress. Returns an error if the multiaddress
/// protocols aren't supported.
fn multiaddr_to_socket(
    addr: &Multiaddr,
) -> Result<impl Future<Output = Result<async_std::net::TcpStream, io::Error>>, ()> {
    let mut iter = addr.iter();
    let proto1 = iter.next().ok_or(())?;
    let proto2 = iter.next().ok_or(())?;

    if iter.next().is_some() {
        return Err(());
    }

    // Ensure ahead of time that the multiaddress is supported.
    match (&proto1, &proto2) {
        (Protocol::Ip4(_), Protocol::Tcp(_))
        | (Protocol::Ip6(_), Protocol::Tcp(_))
        | (Protocol::Dns(_), Protocol::Tcp(_))
        | (Protocol::Dns4(_), Protocol::Tcp(_))
        | (Protocol::Dns6(_), Protocol::Tcp(_)) => {}
        _ => return Err(()),
    }

    let proto1 = proto1.acquire();
    let proto2 = proto2.acquire();

    Ok(async move {
        match (proto1, proto2) {
            (Protocol::Ip4(ip), Protocol::Tcp(port)) => {
                async_std::net::TcpStream::connect(SocketAddr::new(ip.into(), port)).await
            }
            (Protocol::Ip6(ip), Protocol::Tcp(port)) => {
                async_std::net::TcpStream::connect(SocketAddr::new(ip.into(), port)).await
            }
            // TODO: for DNS, do things a bit more explicitly? with for example a library that does the resolution?
            // TODO: differences between DNS, DNS4, DNS6 not respected
            (Protocol::Dns(addr), Protocol::Tcp(port))
            | (Protocol::Dns4(addr), Protocol::Tcp(port))
            | (Protocol::Dns6(addr), Protocol::Tcp(port)) => {
                async_std::net::TcpStream::connect((&*addr, port)).await
            }
            _ => unreachable!(),
        }
    })
}
