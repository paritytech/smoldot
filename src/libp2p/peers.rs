// Smoldot
// Copyright (C) 2019-2022  Parity Technologies (UK) Ltd.
// SPDX-License-Identifier: GPL-3.0-or-later WITH Classpath-exception-2.0

// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.

// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.

// You should have received a copy of the GNU General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.

//! Network of peers.
//!
//! The [`Peers`] state machine builds on top of the [`libp2p`] module and provides an
//! abstraction over the network based on network identities (i.e. [`PeerId`]s). One can set the
//! list of peers to be connected to and through which notification protocols, and the [`Peers`]
//! struct will try to open or re-open connections with these peers. Once connected, one can use
//! the [`Peers`] to send request or notifications with these peers.
//!
//! # Detailed usage
//!
//! The [`Peers`] struct contains six different collections:
//!
//! - A list, decided by the API user, of peers that are marked as "desired".
//! - A list, decided by the API user, of `(peer_id, notification_protocol)` tuples that are
//! marked as "desired".
//! - A list of connections identified by [`ConnectionId`]s.
//! - A list of requests for inbound substreams, identified by a [`DesiredInNotificationId`].
//! When a peer desired to open a notification substream with the local node, a
//! [`DesiredInNotificationId`] is generated by the [`Peers`]. The API user must answer by either
//! accepting or refusing the request. The requests can automatically become obsolete if the
//! remote decides to withdraw their request or the connection closes. A request becoming obsolete
//! does *not* invalidate its [`DesiredInNotificationId`].
//! - A list of requests for outbound substreams emitted by the local node, identified by a
//! [`DesiredOutNotificationId`]. Must be responded using [`Peers::open_out_notification`].
//! - A list of requests that have been received, identified by a [`InRequestId`]. The API user
//! must answer by calling [`Peers::respond_in_request`]. Requests can automatically become
//! obsolete if the remote decides to withdraw their request or the connection closes. A request
//! becoming obsolete does *not* invalidate its [`InRequestId`].
//!

use crate::libp2p::{self, collection, PeerId};
use crate::util::SipHasherBuild;

use alloc::{
    collections::{btree_map, BTreeMap, BTreeSet, VecDeque},
    string::String,
    vec::Vec,
};
use core::{
    num::NonZeroU32,
    ops::{self, Add, Sub},
    time::Duration,
};
use rand::{Rng as _, SeedableRng as _};

pub use collection::{
    ConfigRequestResponse, ConfigRequestResponseIn, ConnectionId, ConnectionTask,
    ConnectionToCoordinator, CoordinatorToConnection, InboundError, NotificationProtocolConfig,
    NotificationsInClosedErr, NotificationsOutErr, ReadWrite, RequestError, SubstreamId,
};

/// Configuration for a [`Peers`].
pub struct Config {
    /// Seed for the randomness within the networking state machine.
    pub randomness_seed: [u8; 32],

    /// Capacity to initially reserve to the list of connections.
    pub connections_capacity: usize,

    /// Capacity to initially reserve to the list of peers.
    pub peers_capacity: usize,

    pub notification_protocols: Vec<NotificationProtocolConfig>,

    pub request_response_protocols: Vec<ConfigRequestResponse>,

    /// Name of the ping protocol on the network.
    pub ping_protocol: String,

    /// Amount of time after which a connection handshake is considered to have taken too long
    /// and must be aborted.
    pub handshake_timeout: Duration,

    /// Key used for the encryption layer.
    /// This is a Noise static key, according to the Noise specification.
    /// Signed using the actual libp2p key.
    pub noise_key: libp2p::connection::NoiseKey,
}

pub struct Peers<TConn, TNow> {
    /// Underlying state machine that manages connections.
    inner: collection::Network<Connection<TConn>, TNow>,

    /// List of all peer identities known to the state machine.
    peers: slab::Slab<Peer>,

    /// For each known peer, the corresponding index within [`Peers::peers`].
    ///
    /// We split the list of peers in two in order to avoid doing extensive hashmap lookups when
    /// it's not necessary.
    peer_indices: hashbrown::HashMap<PeerId, usize, SipHasherBuild>,

    /// List of all established connections, as a tuple of `(peer_index, connection_id)`.
    /// `peer_index` is the index in [`Peers::peers`]. Values are `bool` indicating whether the
    /// connection is fully established: `true` if fully established, `false` if handshaking.
    ///
    /// Note that incoming handshaking connections are never in this list, as their expected
    /// peer id isn't known before the end of the handshake.
    connections_by_peer: BTreeMap<(usize, collection::ConnectionId), bool>,

    /// Keys are combinations of `(peer_index, notifications_protocol_index)`. Contains all the
    /// inbound notification substreams that are either pending or accepted. Used in order to
    /// prevent a peer from opening multiple inbound substreams.
    peers_notifications_in: BTreeSet<(usize, usize)>,

    /// For each inner notification protocol substream, the connection id and the
    /// `notifications_protocol_index`.
    ///
    /// This applies to both inbound and outbound notification substreams.
    // TODO: this could be a user data in `collection`
    inner_notification_substreams: hashbrown::HashMap<
        collection::SubstreamId,
        (collection::ConnectionId, usize),
        fnv::FnvBuildHasher,
    >,

    /// Keys are combinations of `(peer_index, notifications_protocol_index)`. Values are the
    /// state of the corresponding outbound notifications substream.
    peers_notifications_out: BTreeMap<(usize, usize), NotificationsOutState>,

    /// Each [`DesiredInNotificationId`] points to this slab. Contains the connection and
    /// substream id to accept or refuse. Items are always initially set to `Some`, but they can
    /// be set to `None` if the remote cancels its request.
    desired_in_notifications: slab::Slab<Option<(collection::SubstreamId, usize, usize)>>,

    /// Each [`DesiredOutNotificationId`] points to this slab.
    // TODO: doc
    desired_out_notifications: slab::Slab<Option<(usize, collection::ConnectionId, usize)>>,

    /// When a [`DesiredOutNotificationId`] is allocated, the parameters of the desired out
    /// notification are added to this FIFO queue.
    /// This list is later processed in the [`Peers::next_unfulfilled_desired_outbound_substream`]
    /// function.
    // TODO: explain why it can't grow unbounded
    pending_desired_out_notifs: VecDeque<(DesiredOutNotificationId, usize, usize)>,
}

/// See [`Peers::peers_notifications_out`].
///
/// Note that the state where `desired` is `true` and `open` is `Closed` means that the remote
/// has refused or has closed the substream.
struct NotificationsOutState {
    desired: bool,
    open: NotificationsOutOpenState,
}

enum NotificationsOutOpenState {
    Closed,
    ApiHandshakeWait(DesiredOutNotificationId),
    Opening(collection::SubstreamId),
    Open(collection::SubstreamId),
}

/// See [`Peers::peers`]
struct Peer {
    peer_id: PeerId,
    desired: bool,
}

struct Connection<TConn> {
    /// Index in [`Peers::peers`] of the peer this connection is connected to.
    ///
    /// - If the handshake is finished, contains the actual peer.
    /// - If the handshake is in progress and the connection is outbound, contains the *expected*
    /// peer, which might not be the same as the actual.
    /// - If the handshake is in progress and the connection is inbound, contains `None`.
    peer_index: Option<usize>,

    user_data: TConn,
}

impl<TConn, TNow> Peers<TConn, TNow>
where
    TConn: Clone,
    TNow: Clone + Add<Duration, Output = TNow> + Sub<TNow, Output = Duration> + Ord,
{
    /// Creates a new [`Peers`].
    pub fn new(config: Config) -> Self {
        let mut randomness = rand_chacha::ChaCha20Rng::from_seed(config.randomness_seed);

        Peers {
            inner: collection::Network::new(collection::Config {
                capacity: config.connections_capacity,
                noise_key: config.noise_key,
                notification_protocols: config.notification_protocols,
                request_response_protocols: config.request_response_protocols,
                ping_protocol: config.ping_protocol,
                handshake_timeout: config.handshake_timeout,
                randomness_seed: randomness.sample(rand::distributions::Standard),
            }),
            connections_by_peer: BTreeMap::new(),
            peer_indices: hashbrown::HashMap::with_capacity_and_hasher(
                config.peers_capacity,
                SipHasherBuild::new(randomness.sample(rand::distributions::Standard)),
            ),
            peers: slab::Slab::with_capacity(config.peers_capacity),
            inner_notification_substreams: hashbrown::HashMap::with_capacity_and_hasher(
                0,
                Default::default(),
            ), // TODO: capacity?
            peers_notifications_out: BTreeMap::new(),
            peers_notifications_in: BTreeSet::new(),
            pending_desired_out_notifs: VecDeque::new(), // TODO: capacity?
            desired_in_notifications: slab::Slab::new(), // TODO: capacity?
            desired_out_notifications: slab::Slab::new(), // TODO: capacity?
        }
    }

    /// Returns the list the overlay networks originally passed as
    /// [`Config::notification_protocols`].
    pub fn notification_protocols(
        &self,
    ) -> impl ExactSizeIterator<Item = &NotificationProtocolConfig> {
        self.inner.notification_protocols()
    }

    /// Returns the list the request-response protocols originally passed as
    /// [`Config::request_response_protocols`].
    pub fn request_response_protocols(
        &self,
    ) -> impl ExactSizeIterator<Item = &ConfigRequestResponse> {
        self.inner.request_response_protocols()
    }

    /// Returns the Noise key originally passed as [`Config::noise_key`].
    pub fn noise_key(&self) -> &libp2p::connection::NoiseKey {
        self.inner.noise_key()
    }

    /// Pulls a message that must be sent to a connection.
    ///
    /// The message must be passed to [`ConnectionTask::inject_coordinator_message`] in the
    /// appropriate connection.
    ///
    /// This function guarantees that the [`ConnectionId`] always refers to a connection that
    /// is still alive, in the sense that [`ConnectionTask::inject_coordinator_message`] has
    /// never returned `None`.
    pub fn pull_message_to_connection(
        &mut self,
    ) -> Option<(ConnectionId, CoordinatorToConnection<TNow>)> {
        self.inner.pull_message_to_connection()
    }

    /// Injects into the state machine a message generated by
    /// [`ConnectionTask::pull_message_to_coordinator`].
    ///
    /// This message is queued and is later processed in [`Peers::next_event`]. This means that
    /// it is [`Peers::next_event`] and not [`Peers::inject_connection_message`] that updates
    /// the internals of the state machine according to the content of the message. For example,
    /// if a [`ConnectionTask`] sends a message to the coordinator indicating that a notifications
    /// substream has been closed, the coordinator will still believe that it is open until
    /// [`Peers::next_event`] processes this message and at the same time returns a corresponding
    /// [`Event`]. Processing messages directly in [`Peers::inject_connection_message`] would
    /// introduce "race conditions" where the API user can't be sure in which state a connection
    /// or a substream is.
    pub fn inject_connection_message(
        &mut self,
        connection_id: ConnectionId,
        message: ConnectionToCoordinator,
    ) {
        self.inner.inject_connection_message(connection_id, message)
    }

    /// Returns the next event produced by the service.
    pub fn next_event(&mut self) -> Option<Event<TConn>> {
        loop {
            let event = match self.inner.next_event() {
                Some(ev) => ev,
                None => return None,
            };

            match event {
                collection::Event::HandshakeFinished {
                    id: connection_id,
                    peer_id,
                } => {
                    let actual_peer_index = self.peer_index_or_insert(&peer_id);
                    let peer_id = self.peers[actual_peer_index].peer_id.clone();

                    if let Some(expected_peer_index) = self.inner[connection_id].peer_index {
                        if expected_peer_index != actual_peer_index {
                            let _was_in = self
                                .connections_by_peer
                                .remove(&(expected_peer_index, connection_id));
                            debug_assert_eq!(_was_in, Some(false));
                            let _was_in = self
                                .connections_by_peer
                                .insert((actual_peer_index, connection_id), true);
                            debug_assert!(_was_in.is_none());
                            self.inner[connection_id].peer_index = Some(actual_peer_index);

                            // TODO: report some kind of error on the outer API layers?
                        } else {
                            let _was_in = self
                                .connections_by_peer
                                .insert((actual_peer_index, connection_id), true);
                            debug_assert_eq!(_was_in, Some(false));
                        }
                    } else {
                        let _was_in = self
                            .connections_by_peer
                            .insert((actual_peer_index, connection_id), true);
                        debug_assert!(_was_in.is_none());
                        self.inner[connection_id].peer_index = Some(actual_peer_index);
                    }

                    let num_peer_connections = {
                        let num = self
                            .connections_by_peer
                            .range(
                                (actual_peer_index, collection::ConnectionId::min_value())
                                    ..=(actual_peer_index, collection::ConnectionId::max_value()),
                            )
                            .filter(|(_, established)| **established)
                            .count();
                        NonZeroU32::new(u32::try_from(num).unwrap()).unwrap()
                    };

                    // If there isn't any other connection with this peer yet, check the desired
                    // substreams and open them.
                    if num_peer_connections.get() == 1 {
                        let notification_protocols_indices = self
                            .peers_notifications_out
                            .range(
                                (actual_peer_index, usize::min_value())
                                    ..=(actual_peer_index, usize::max_value()),
                            )
                            .filter(|(_, v)| {
                                // Since this check happens only at the first connection, all
                                // substreams are necessarily closed.
                                debug_assert!(matches!(v.open, NotificationsOutOpenState::Closed));
                                v.desired
                            })
                            .map(|((_, index), _)| *index)
                            .collect::<Vec<_>>();

                        for idx in notification_protocols_indices {
                            let id = DesiredOutNotificationId(
                                self.desired_out_notifications.insert(Some((
                                    actual_peer_index,
                                    connection_id,
                                    idx,
                                ))),
                            );

                            self.peers_notifications_out
                                .get_mut(&(actual_peer_index, idx))
                                .unwrap()
                                .open = NotificationsOutOpenState::ApiHandshakeWait(id);

                            self.pending_desired_out_notifs
                                .push_back((id, actual_peer_index, idx));
                        }
                    }

                    return Some(Event::Connected {
                        num_peer_connections,
                        peer_id,
                    });
                }

                collection::Event::StartShutdown { .. } => {
                    // TODO: mark connection as shutting down so that we don't start any new request or substream; in practice this can't happen right now because events are processed in a loop, but in theory the user could do something stupid and get a panic
                }

                collection::Event::Shutdown {
                    id: connection_id,
                    user_data:
                        Connection {
                            peer_index: Some(expected_peer_index),
                            user_data,
                        },
                } => {
                    // `expected_peer_index` is `None` iff the connection was an incoming
                    // connection whose handshake isn't finished yet.

                    let was_established = self
                        .connections_by_peer
                        .remove(&(expected_peer_index, connection_id))
                        .unwrap();

                    let peer_id = self.peers[expected_peer_index].peer_id.clone();

                    let num_peer_connections = {
                        let num = self
                            .connections_by_peer
                            .range(
                                (expected_peer_index, collection::ConnectionId::min_value())
                                    ..=(expected_peer_index, collection::ConnectionId::max_value()),
                            )
                            .filter(|(_, established)| **established)
                            .count();
                        u32::try_from(num).unwrap()
                    };

                    self.try_clean_up_peer(expected_peer_index);

                    // Only produce a `Disconnected` event if connection wasn't handshaking.
                    if was_established {
                        return Some(Event::Disconnected {
                            num_peer_connections,
                            peer_id,
                            user_data,
                        });
                    }
                }

                collection::Event::Shutdown {
                    user_data:
                        Connection {
                            peer_index: None, ..
                        },
                    ..
                } => {
                    // Connection was incoming but its handshake wasn't finished yet.
                    // The shutdown isn't reported.
                }

                collection::Event::InboundError {
                    id: connection_id,
                    error,
                } => {
                    let peer_id = {
                        let peer_index = self.inner[connection_id].peer_index.unwrap();
                        self.peers[peer_index].peer_id.clone()
                    };

                    return Some(Event::InboundError {
                        peer_id,
                        connection_id,
                        error,
                    });
                }

                collection::Event::Response {
                    substream_id,
                    response,
                } => {
                    return Some(Event::Response {
                        request_id: OutRequestId(substream_id),
                        response,
                    });
                }

                collection::Event::RequestIn {
                    id: connection_id,
                    substream_id,
                    protocol_index,
                    request_payload,
                } => {
                    let peer_id = {
                        // Incoming requests can only happen if the connection is no longer
                        // handshaking, in which case `peer_index` is guaranteed to be `Some`.
                        let peer_index = self.inner[connection_id].peer_index.unwrap();
                        self.peers[peer_index].peer_id.clone()
                    };

                    return Some(Event::RequestIn {
                        peer_id,
                        connection_id,
                        protocol_index,
                        request_id: InRequestId(substream_id),
                        request_payload,
                    });
                }

                collection::Event::RequestInCancel { substream_id } => {
                    return Some(Event::RequestInCancel {
                        id: InRequestId(substream_id),
                    })
                }

                collection::Event::NotificationsOutResult {
                    substream_id,
                    result,
                } => {
                    let (connection_id, notifications_protocol_index) = *self
                        .inner_notification_substreams
                        .get(&substream_id)
                        .unwrap();
                    let peer_index = self.inner[connection_id].peer_index.unwrap();
                    let notification_out = self
                        .peers_notifications_out
                        .get_mut(&(peer_index, notifications_protocol_index))
                        .unwrap();
                    let desired = notification_out.desired;

                    debug_assert!(matches!(
                        notification_out.open,
                        NotificationsOutOpenState::Opening(_)
                    ));

                    if result.is_ok() {
                        notification_out.open = NotificationsOutOpenState::Open(substream_id);
                        // TODO: close if `!desired`
                    } else {
                        notification_out.open = NotificationsOutOpenState::Closed;
                        self.inner_notification_substreams
                            .remove(&substream_id)
                            .unwrap();

                        // Remove entry from map if it has become useless.
                        if !desired {
                            self.peers_notifications_out
                                .remove(&(peer_index, notifications_protocol_index));
                        }
                    }

                    return Some(Event::NotificationsOutResult {
                        peer_id: self.peers[peer_index].peer_id.clone(),
                        notifications_protocol_index,
                        result,
                    });
                }

                collection::Event::NotificationsOutCloseDemanded { substream_id }
                | collection::Event::NotificationsOutReset { substream_id } => {
                    // If the remote asks the substream to be closed, we immediately respond
                    // accordingly without asking the higher level user. This is an opinionated
                    // decision that could be changed in the future.
                    if let collection::Event::NotificationsOutCloseDemanded { .. } = event {
                        self.inner.close_out_notifications(substream_id);
                    }

                    let (connection_id, notifications_protocol_index) = self
                        .inner_notification_substreams
                        .remove(&substream_id)
                        .unwrap();
                    let peer_index = self.inner[connection_id].peer_index.unwrap();
                    let notification_out = self
                        .peers_notifications_out
                        .get_mut(&(peer_index, notifications_protocol_index))
                        .unwrap();

                    debug_assert!(matches!(
                        notification_out.open,
                        NotificationsOutOpenState::Open(_)
                    ));
                    notification_out.open = NotificationsOutOpenState::Closed;

                    // Remove entry from map if it has become useless.
                    if !notification_out.desired {
                        self.peers_notifications_out
                            .remove(&(peer_index, notifications_protocol_index));
                    }

                    return Some(Event::NotificationsOutClose {
                        peer_id: self.peers[peer_index].peer_id.clone(),
                        notifications_protocol_index,
                    });
                }

                collection::Event::NotificationsInOpen {
                    id: connection_id,
                    substream_id,
                    notifications_protocol_index,
                    remote_handshake: handshake,
                    ..
                } => {
                    // Incoming substreams can only happen if the connection is no longer
                    // handshaking, in which case `peer_index` is guaranteed to be `Some`.
                    let peer_index = self.inner[connection_id].peer_index.unwrap();

                    // If this peer has already opened an inbound notifications substream in the
                    // past, forbid any additional one.
                    if self
                        .peers_notifications_in
                        .contains(&(peer_index, notifications_protocol_index))
                    {
                        self.inner.reject_in_notifications(substream_id);
                        continue;
                    }

                    self.peers_notifications_in
                        .insert((peer_index, notifications_protocol_index));

                    let desired_notif_id =
                        DesiredInNotificationId(self.desired_in_notifications.insert(Some((
                            substream_id,
                            peer_index,
                            notifications_protocol_index,
                        ))));

                    let _was_in = self
                        .inner_notification_substreams
                        .insert(substream_id, (connection_id, notifications_protocol_index));
                    debug_assert!(_was_in.is_none());

                    return Some(Event::DesiredInNotification {
                        id: desired_notif_id,
                        peer_id: self.peers[peer_index].peer_id.clone(),
                        notifications_protocol_index,
                        handshake,
                    });
                }

                collection::Event::NotificationsIn {
                    substream_id,
                    notification,
                } => {
                    let (connection_id, notifications_protocol_index) = *self
                        .inner_notification_substreams
                        .get(&substream_id)
                        .unwrap();

                    let peer_id = {
                        // Incoming notifications can only happen if the connection is no longer
                        // handshaking, in which case `peer_index` is guaranteed to be `Some`.
                        let peer_index = self.inner[connection_id].peer_index.unwrap();
                        self.peers[peer_index].peer_id.clone()
                    };

                    return Some(Event::NotificationsIn {
                        peer_id,
                        notifications_protocol_index,
                        notification,
                    });
                }

                collection::Event::NotificationsInClose {
                    substream_id,
                    outcome,
                } => {
                    let (connection_id, notifications_protocol_index) = self
                        .inner_notification_substreams
                        .remove(&substream_id)
                        .unwrap();

                    let peer_index = {
                        // Incoming substreams can only happen if the connection is no longer
                        // handshaking, in which case `peer_index` is guaranteed to be `Some`.
                        self.inner[connection_id].peer_index.unwrap()
                    };

                    // TODO: this is O(n)
                    for (_, item) in self.desired_in_notifications.iter_mut() {
                        if let Some((_, idx, _)) = *item {
                            if idx == peer_index {
                                *item = None;
                            }
                        }
                    }

                    let _was_in = self
                        .peers_notifications_in
                        .remove(&(peer_index, notifications_protocol_index));
                    assert!(_was_in);

                    return Some(Event::NotificationsInClose {
                        peer_id: self.peers[peer_index].peer_id.clone(),
                        notifications_protocol_index,
                        outcome,
                    });
                }

                collection::Event::PingOutSuccess { .. } => {
                    // We don't care about or report successful pings at the moment.
                }

                collection::Event::PingOutFailed { id } => {
                    // A failed ping leads to a disconnect.
                    self.inner.start_shutdown(id);
                }
            }
        }
    }

    /// Inserts an incoming connection in the state machine.
    ///
    /// This connection hasn't finished handshaking and the [`PeerId`] of the remote isn't known
    /// yet.
    ///
    /// Must be passed the moment (as a `TNow`) when the connection as been established, in order
    /// to determine when the handshake timeout expires.
    pub fn add_incoming_connection(
        &mut self,
        when_connected: TNow,
        user_data: TConn,
    ) -> (ConnectionId, ConnectionTask<TNow>) {
        self.inner.insert(
            when_connected,
            false,
            Connection {
                peer_index: None,
                user_data,
            },
        )
    }

    /// Inserts an outgoing connection in the state machine.
    ///
    /// This connection hasn't finished handshaking, and the [`PeerId`] of the remote isn't known
    /// yet, but it is expected to be in `unfulfilled_desired_peers`. After this function has been
    /// called, the provided `expected_peer_id` will no longer be part of the return value of
    /// [`Peers::unfulfilled_desired_peers`].
    ///
    /// Must be passed the moment (as a `TNow`) when the connection as been established, in order
    /// to determine when the handshake timeout expires.
    pub fn add_outgoing_connection(
        &mut self,
        when_connected: TNow,
        expected_peer_id: &PeerId,
        user_data: TConn,
    ) -> (ConnectionId, ConnectionTask<TNow>) {
        let peer_index = self.peer_index_or_insert(expected_peer_id);

        let (connection_id, connection_task) = self.inner.insert(
            when_connected,
            true,
            Connection {
                peer_index: Some(peer_index),
                user_data,
            },
        );

        debug_assert!(!self
            .connections_by_peer
            .contains_key(&(peer_index, connection_id)));
        self.connections_by_peer
            .insert((peer_index, connection_id), false);

        (connection_id, connection_task)
    }

    /// Returns the list of [`PeerId`]s that have been marked as desired, but that don't have any
    /// associated connection. An associated connection is either a fully established connection
    /// with that peer, or an outgoing connection that is still handshaking but expects to reach
    /// that peer.
    pub fn unfulfilled_desired_peers(&self) -> impl Iterator<Item = &PeerId> {
        // TODO: complexity of this method is too damn high

        let mut desired = self
            .peers
            .iter()
            .filter(|(_, p)| p.desired)
            .map(|(peer_index, _)| peer_index)
            .collect::<BTreeSet<_>>();

        for ((peer_index, _), state) in &self.peers_notifications_out {
            if state.desired {
                desired.insert(*peer_index);
            }
        }

        let mut out = Vec::with_capacity(desired.len());
        for peer_index in desired {
            if self
                .connections_by_peer
                .range(
                    (peer_index, ConnectionId::min_value())
                        ..=(peer_index, ConnectionId::max_value()),
                )
                .count()
                != 0
            {
                continue;
            }

            out.push(&self.peers[peer_index].peer_id);
        }

        out.into_iter()
    }

    /// Sets the "desired" flag of the given [`PeerId`].
    ///
    /// When a peer is marked as "desired" and there isn't any pending or established connection
    /// towards it, it is returned when calling [`Peers::unfulfilled_desired_peers`].
    pub fn set_peer_desired(&mut self, peer_id: &PeerId, desired: bool) {
        let peer_index = self.peer_index_or_insert(peer_id);
        self.peers[peer_index].desired = desired;
        if !desired {
            self.try_clean_up_peer(peer_index);
        }
    }

    /// Sets the given combinations of notification protocol and [`PeerId`] as "desired".
    ///
    /// When a peer is marked as "desired" and there isn't any pending or established connection
    /// towards it, it is returned when calling [`Peers::unfulfilled_desired_peers`].
    ///
    /// When a combination of network protocol and [`PeerId`] is marked as "desired", the state
    /// machine will try to maintain open an outbound substream. If the remote refuses the
    /// substream, it will be returned when calling [`Peers::refused_notifications_out`].
    ///
    /// This function might generate a message destined to a connection. Use
    /// [`Peers::pull_message_to_connection`] to process these messages after it has returned.
    pub fn set_peer_notifications_out_desired(
        &mut self,
        peer_id: &PeerId,
        notification_protocol: usize,
        new_desired_state: DesiredState,
    ) {
        let peer_index = self.peer_index_or_insert(peer_id);

        let current_state = self
            .peers_notifications_out
            .entry((peer_index, notification_protocol));

        if matches!(
            new_desired_state,
            DesiredState::Desired | DesiredState::DesiredReset
        ) {
            // Do nothing if it was already desired.
            match (&current_state, new_desired_state) {
                (btree_map::Entry::Occupied(e), DesiredState::Desired) if e.get().desired => return,
                _ => {}
            }

            let current_state = current_state.or_insert(NotificationsOutState {
                desired: true,
                open: NotificationsOutOpenState::Closed,
            });
            current_state.desired = true;

            // If substream is closed, try to open it.
            if matches!(current_state.open, NotificationsOutOpenState::Closed) {
                if let Some(connection_id) = self.connection_id_for_peer(peer_id) {
                    let id =
                        DesiredOutNotificationId(self.desired_out_notifications.insert(Some((
                            peer_index,
                            connection_id,
                            notification_protocol,
                        ))));

                    // TODO: should use `current_state` instead, but this causes difficulties calling `connection_id_for_peer`
                    self.peers_notifications_out
                        .get_mut(&(peer_index, notification_protocol))
                        .unwrap()
                        .open = NotificationsOutOpenState::ApiHandshakeWait(id);

                    self.pending_desired_out_notifs.push_back((
                        id,
                        peer_index,
                        notification_protocol,
                    ));
                }
            }
        } else {
            // Do nothing if not desired.
            let current_state = match current_state {
                btree_map::Entry::Occupied(e) if e.get().desired => e.into_mut(),
                _ => return,
            };

            current_state.desired = false;

            match current_state.open {
                NotificationsOutOpenState::ApiHandshakeWait(id) => {
                    debug_assert!(self.desired_out_notifications[id.0].is_some());
                    self.desired_out_notifications[id.0] = None;
                }
                NotificationsOutOpenState::Closed => {}
                NotificationsOutOpenState::Open(substream_id)
                | NotificationsOutOpenState::Opening(substream_id) => {
                    self.inner.close_out_notifications(substream_id);
                    current_state.open = NotificationsOutOpenState::Closed;
                }
            }

            self.try_clean_up_peer(peer_index);
        }
    }

    /// Returns the combinations of notification and [`PeerId`] that are marked as "desired", but
    /// where the remote has refused the request for a notifications substream.
    ///
    /// Use [`Peers::set_peer_notifications_out_desired`] with [`DesiredState::DesiredReset`] in
    /// order to try again.
    pub fn refused_notifications_out(&mut self) -> impl Iterator<Item = (PeerId, usize)> {
        // TODO: O(n)
        let peers = &self.peers;
        self.peers_notifications_out
            .iter()
            .filter_map(|((peer_index, notif_proto_index), value)| {
                if !value.desired || !matches!(value.open, NotificationsOutOpenState::Closed) {
                    return None;
                }

                let peer_id = peers[*peer_index].peer_id.clone();
                Some((peer_id, *notif_proto_index))
            })
            .collect::<Vec<_>>()
            .into_iter()
    }

    /// Responds to an [`Event::DesiredInNotification`] by accepting the request for an inbound
    /// substream.
    ///
    /// If `Ok` is returned, the substream is now considered open. If `Err` is returned, then
    /// no substream has been opened.
    ///
    /// This function might generate a message destined to a connection. Use
    /// [`Peers::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Panic
    ///
    /// Panics if the [`DesiredInNotificationId`] is invalid. Note that these ids remain valid
    /// forever until [`Peers::in_notification_accept`] or [`Peers::in_notification_refuse`] is
    /// called.
    ///
    pub fn in_notification_accept(
        &mut self,
        id: DesiredInNotificationId,
        handshake_back: Vec<u8>,
    ) -> Result<(), InNotificationAcceptError> {
        let (substream_id, _, _) = match self.desired_in_notifications.remove(id.0) {
            Some(v) => v,
            None => {
                return Err(InNotificationAcceptError::Obsolete);
            }
        };

        self.inner
            .accept_in_notifications(substream_id, handshake_back);

        Ok(())
    }

    /// Responds to an [`Event::DesiredInNotification`] by refusing the request for an inbound
    /// substream.
    ///
    /// This function might generate a message destined to a connection. Use
    /// [`Peers::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Panic
    ///
    /// Panics if the [`DesiredInNotificationId`] is invalid. Note that these ids remain valid
    /// forever until [`Peers::in_notification_accept`] or [`Peers::in_notification_refuse`] is
    /// called.
    ///
    pub fn in_notification_refuse(&mut self, id: DesiredInNotificationId) {
        assert!(self.desired_in_notifications.contains(id.0));

        let (substream_id, peer_index, notifications_protocol_index) =
            match self.desired_in_notifications.remove(id.0) {
                Some(v) => v,
                None => {
                    return;
                }
            };

        self.inner.reject_in_notifications(substream_id);

        self.peers_notifications_in
            .remove(&(peer_index, notifications_protocol_index));
        let _was_in = self.inner_notification_substreams.remove(&substream_id);
        debug_assert!(_was_in.is_some());
    }

    /// Finds a peer-substream combination marked as desired where there exists a connection to
    /// this peer but the desired substream hasn't been opened yet.
    /// If one is found, allocates a [`DesiredOutNotificationId`] that must be answered using
    /// [`Peers::open_out_notification`].
    ///
    /// The allocated [`DesiredOutNotificationId`] remains valid forever until
    /// [`Peers::open_out_notification`] is called.
    ///
    /// > **Note**: It is not possible to *not* open a desired outbound substream after it has
    /// >           been returned by this function. This function and
    /// >           [`Peers::open_out_notification`] are an API trick in order for the [`Peers`]
    /// >           to fetch the content of the handshake to send to the remote.
    pub fn next_unfulfilled_desired_outbound_substream(
        &mut self,
    ) -> Option<(DesiredOutNotificationId, &PeerId, usize)> {
        let (id, peer_index, notifications_protocol_index) =
            self.pending_desired_out_notifs.pop_front()?;
        Some((
            id,
            &self.peers[peer_index].peer_id,
            notifications_protocol_index,
        ))
    }

    /// Continuation of calling [`Peers::next_unfulfilled_desired_outbound_substream`] by
    /// indicating the handshake to send to the remote.
    ///
    /// Must be passed the current moment in time in order to determine when the operation of
    /// opening the substream times out.
    ///
    /// This function might generate a message destined to a connection. Use
    /// [`Peers::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Panic
    ///
    /// Panics if the [`DesiredOutNotificationId`] is invalid. Note that these ids remain valid
    /// forever until [`Peers::open_out_notification`] is called.
    ///
    pub fn open_out_notification(
        &mut self,
        id: DesiredOutNotificationId,
        now: TNow,
        handshake: Vec<u8>,
    ) {
        let (peer_index, connection_id, notifications_protocol_index) =
            match self.desired_out_notifications.remove(id.0) {
                Some(v) => v,
                None => {
                    // The "notification out request" is obsolete.
                    return;
                }
            };

        let notif_state = self
            .peers_notifications_out
            .get_mut(&(peer_index, notifications_protocol_index))
            .unwrap();
        debug_assert!(matches!(
            notif_state.open,
            NotificationsOutOpenState::ApiHandshakeWait(_)
        ));

        let substream_id = self.inner.open_out_notifications(
            connection_id,
            notifications_protocol_index,
            now,
            handshake,
        );

        let _prev_value = self
            .inner_notification_substreams
            .insert(substream_id, (connection_id, notifications_protocol_index));
        debug_assert!(_prev_value.is_none());

        notif_state.open = NotificationsOutOpenState::Opening(substream_id);
    }

    ///
    /// This function might generate a message destined to a connection. Use
    /// [`Peers::pull_message_to_connection`] to process these messages after it has returned.
    // TODO: document
    pub fn queue_notification(
        &mut self,
        target: &PeerId,
        notifications_protocol_index: usize,
        notification: impl Into<Vec<u8>>,
    ) -> Result<(), QueueNotificationError> {
        let peer_index = *self.peer_indices.get(target).unwrap();

        let substream_id = match self
            .peers_notifications_out
            .get(&(peer_index, notifications_protocol_index))
            .map(|state| &state.open)
        {
            None
            | Some(
                NotificationsOutOpenState::Opening(_)
                | NotificationsOutOpenState::Closed
                | NotificationsOutOpenState::ApiHandshakeWait(_),
            ) => panic!(),
            Some(NotificationsOutOpenState::Open(s_id)) => s_id,
        };

        let result = self.inner.queue_notification(*substream_id, notification);

        match result {
            Ok(()) => Ok(()),
            Err(collection::QueueNotificationError::QueueFull) => {
                Err(QueueNotificationError::QueueFull)
            }
        }
    }

    /// Equivalent to calling [`Peers::queue_notification`] for all peers an outbound
    /// notifications substream is open with.
    ///
    /// Individual errors that would have occurred when calling [`Peers::queue_notification`] are
    /// silently discarded.
    ///
    /// This function might generate messages destined to connections. Use
    /// [`Peers::pull_message_to_connection`] to process these messages after it has returned.
    // TODO: consider returning the peers we successfully sent to
    pub fn broadcast_notification(
        &mut self,
        notifications_protocol_index: usize,
        notification: impl Into<Vec<u8>>,
    ) {
        let notification = notification.into();

        // TODO: implement this better; this is O(n)
        for ((_, notif_proto_index), state) in self.peers_notifications_out.iter() {
            if *notif_proto_index != notifications_protocol_index {
                continue;
            }

            if let NotificationsOutOpenState::Open(substream_id) = &state.open {
                let _ = self
                    .inner
                    .queue_notification(*substream_id, notification.clone());
            }
        }
    }

    /// Sends a request to the given peer.
    ///
    /// A [`Event::Response`] event will later be generated containing the result of the request.
    ///
    /// It is invalid to start a request on a peer before an [`Event::Connected`] has been
    /// generated, or after a [`Event::Disconnected`] has been generated where
    /// [`Event::Disconnected::num_peer_connections`] is 0.
    ///
    /// Returns a newly-allocated identifier for this request.
    ///
    /// This function generates a message destined to a connection. Use
    /// [`Peers::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Requests
    ///
    /// A request consists in:
    ///
    /// - Opening a substream on an established connection with the target.
    /// - Negotiating the requested protocol (`protocol_index`) on this substream using the
    ///   *multistream-select* protocol.
    /// - Sending the request (`request_data` parameter), prefixed with its length.
    /// - Waiting for the response (prefixed with its length), which is then returned.
    ///
    /// An error happens if the connection closes while the request is in progress, if the remote
    /// doesn't support the given protocol, if the request or response doesn't respect the protocol
    /// limits (see [`ConfigRequestResponse`]), or if the remote takes too much time to answer.
    ///
    /// The timeout is the time between the moment the substream is opened and the moment the
    /// response is sent back. If the emitter doesn't send the request or if the receiver doesn't
    /// answer during this time window, the request is considered failed.
    ///
    /// # Panic
    ///
    /// Panics if `protocol_index` isn't a valid index in [`Config::request_response_protocols`].
    /// Panics if there is no open connection with the target.
    ///
    pub fn start_request(
        &mut self,
        target: &PeerId,
        protocol_index: usize,
        request_data: Vec<u8>,
        timeout: TNow,
    ) -> OutRequestId {
        let target_connection_id = self.connection_id_for_peer(target).unwrap();
        OutRequestId(self.inner.start_request(
            target_connection_id,
            protocol_index,
            request_data,
            timeout,
        ))
    }

    /// Responds to a previously-emitted [`Event::RequestIn`].
    ///
    /// # Panic
    ///
    /// Panics if the [`InRequestId`] is invalid. Note that these ids remain valid forever until
    /// [`Peers::respond_in_request`] is called or a [`Event::RequestInCancel`] is generated.
    ///
    pub fn respond_in_request(&mut self, id: InRequestId, response: Result<Vec<u8>, ()>) {
        self.inner.respond_in_request(id.0, response)
    }

    /// Returns `true` if there exists an established connection with the given peer.
    pub fn has_established_connection(&self, peer: &PeerId) -> bool {
        let peer_index = match self.peer_indices.get(peer) {
            Some(idx) => *idx,
            None => return false,
        };

        self.connections_by_peer
            .range(
                (peer_index, ConnectionId::min_value())
                    ..=(peer_index, ConnectionId::max_value()),
            )
            .any(|(_, established)| *established)
    }

    /// Returns an iterator to the list of [`PeerId`]s that we have an established connection
    /// with.
    pub fn peers_list(&self) -> impl Iterator<Item = &PeerId> {
        self.peers
            .iter()
            .filter(|(peer_index, _)| {
                self.connections_by_peer
                    .range(
                        (*peer_index, ConnectionId::min_value())
                            ..=(*peer_index, ConnectionId::max_value()),
                    )
                    .filter(|(_, established)| **established)
                    .count()
                    != 0
            })
            .map(|(_, p)| &p.peer_id)
    }

    /// Returns the number of connections we have a substream with.
    pub fn num_outgoing_substreams(&self, notifications_protocol_index: usize) -> usize {
        // TODO: O(n)
        self.peers_notifications_out
            .iter()
            .filter(|((_, idx), state)| {
                *idx == notifications_protocol_index
                    && matches!(state.open, NotificationsOutOpenState::Open(_))
            })
            .count()
    }

    /// Picks the connection to use to send requests or notifications to the given peer.
    fn connection_id_for_peer(&self, target: &PeerId) -> Option<collection::ConnectionId> {
        let peer_index = *self.peer_indices.get(target)?;

        if let Some(((_, connection_id), _)) = self
            .connections_by_peer
            .range(
                (peer_index, collection::ConnectionId::min_value())
                    ..=(peer_index, collection::ConnectionId::max_value()),
            )
            .find(|(_, established)| **established)
        {
            return Some(*connection_id);
        }

        None
    }

    fn peer_index_or_insert(&mut self, peer_id: &PeerId) -> usize {
        if let Some(idx) = self.peer_indices.get(peer_id) {
            return *idx;
        }

        let index = self.peers.insert(Peer {
            desired: false,
            peer_id: peer_id.clone(),
        });

        self.peer_indices.insert(peer_id.clone(), index);
        index
    }

    /// Checks the state of the given `peer_index`. If there is no difference between this peer's
    /// state and the default state, removes the peer from the data structure altogether.
    ///
    /// # Panic
    ///
    /// Panics if the given `peer_index` is invalid.
    ///
    fn try_clean_up_peer(&mut self, peer_index: usize) {
        if self.peers[peer_index].desired {
            return;
        }

        if self
            .connections_by_peer
            .range(
                (peer_index, collection::ConnectionId::min_value())
                    ..=(peer_index, collection::ConnectionId::max_value()),
            )
            .count()
            != 0
        {
            return;
        }

        if self
            .peers_notifications_out
            .range((peer_index, usize::min_value())..=(peer_index, usize::max_value()))
            .count()
            != 0
        {
            return;
        }

        let peer_id = self.peers.remove(peer_index).peer_id;
        let _index = self.peer_indices.remove(&peer_id).unwrap();
        debug_assert_eq!(_index, peer_index);
    }
}

impl<TConn, TNow> ops::Index<ConnectionId> for Peers<TConn, TNow> {
    type Output = TConn;
    fn index(&self, id: ConnectionId) -> &TConn {
        &self.inner[id].user_data
    }
}

impl<TConn, TNow> ops::IndexMut<ConnectionId> for Peers<TConn, TNow> {
    fn index_mut(&mut self, id: ConnectionId) -> &mut TConn {
        &mut self.inner[id].user_data
    }
}

/// See [`Event::DesiredInNotification`].
#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct DesiredInNotificationId(usize);

/// See [`Peers::next_unfulfilled_desired_outbound_substream`].
#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct DesiredOutNotificationId(usize);

/// See [`Event::RequestIn`].
#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct InRequestId(collection::SubstreamId);

/// See [`Peers::start_request`].
#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct OutRequestId(collection::SubstreamId);

/// Event happening over the network. See [`Peers::next_event`].
// TODO: in principle we could return `&PeerId` instead of `PeerId` most of the time, but this causes many borrow checker issues in the upper layer and I'm not motivated enough to deal with that
#[derive(Debug)]
pub enum Event<TConn> {
    /// Established a new connection to the given peer.
    Connected {
        /// Identity of the peer on the other side of the connection.
        peer_id: PeerId,

        /// Number of other established connections with the same peer, including the one that
        /// has just been established.
        num_peer_connections: NonZeroU32,
    },

    /// A connection has stopped.
    Disconnected {
        /// Identity of the peer on the other side of the connection.
        peer_id: PeerId,

        /// Number of other established connections with the same peer remaining after the
        /// disconnection.
        num_peer_connections: u32,

        /// User data that was associated to this connection.
        // TODO: ?!
        user_data: TConn,
    },

    /// Received an incoming substream, but this substream has produced an error.
    ///
    /// > **Note**: This event exists only for diagnostic purposes. No action is expected in
    /// >           return.
    InboundError {
        /// Peer which opened the substream.
        peer_id: PeerId,
        /// Identifier of the connection on which the problem happened.
        connection_id: ConnectionId,
        /// Error that happened.
        error: InboundError,
    },

    /// Outcome of a request started using [`Peers::start_request`].
    ///
    /// *All* requests always lead to an outcome, even if the connection has been closed while the
    /// request was in progress.
    Response {
        /// Identifier for this request. Was returned by [`Peers::start_request`].
        request_id: OutRequestId,
        response: Result<Vec<u8>, RequestError>,
    },

    /// Received a request from a request-response protocol.
    RequestIn {
        /// Identifier for this request. Must be passed back when calling
        /// [`Peers::respond_in_request`].
        request_id: InRequestId,
        /// Peer which sent the request.
        peer_id: PeerId,
        /// Identifier of the connection that has sent the request.
        connection_id: ConnectionId,
        /// Request-response protocol the request is about.
        protocol_index: usize,
        /// Payload of the request, opaque to this state machine.
        ///
        /// > **Note**: Keep in mind that this data is untrusted.
        request_payload: Vec<u8>,
    },

    /// A previously-emitted [`Event::RequestIn`] is now obsolete.
    ///
    /// The [`InRequestId`] is now considered dead, and calling [`Peers::respond_in_request`] is
    /// now invalid.
    RequestInCancel {
        /// Identifier for this request.
        id: InRequestId,
    },

    /// A peer would like to open a notifications substream with the local node, in order to
    /// send notifications.
    ///
    /// Only one inbound notifications substream can exist per peer and per protocol. Any
    /// additional one will be automatically refused.
    DesiredInNotification {
        /// Identifier for this request. Must be passed back when calling
        /// [`Peers::in_notification_accept`] or [`Peers::in_notification_refuse`].
        id: DesiredInNotificationId,
        /// Peer which tries to open an inbound substream.
        peer_id: PeerId,
        /// Notifications protocol the substream is about.
        notifications_protocol_index: usize,
        /// Handshake of the request sent by the peer. Opaque to this state machine.
        ///
        /// > **Note**: Keep in mind that this data is untrusted.
        handshake: Vec<u8>,
    },

    /// A previously-emitted [`DesiredInNotificationId`] is now obsolete. This event is for
    /// informative purpose and does **not** invalidate the [`DesiredInNotificationId`]. Use
    /// [`Peers::in_notification_refuse`] if you no longer care about this request.
    DesiredInNotificationCancel {
        /// Identifier for this request.
        id: DesiredInNotificationId,
    },

    /// A handshaking outbound substream has been accepted by the remote.
    ///
    /// Will happen for combinations of [`PeerId`] and notification protocols that have been
    /// marked as desired. Can also happen for other combinations, if there were marked as desired
    /// in the past but no longer are.
    ///
    /// If `Ok`, it is now possible to send notifications on this substream.
    NotificationsOutResult {
        /// Peer the substream is open with.
        peer_id: PeerId,
        /// Notifications protocol the substream is about.
        notifications_protocol_index: usize,
        /// If `Ok`, contains the handshake sent back by the remote. Its interpretation is out of
        /// scope of this module.
        /// If `Err`, the state machine will *not* automatically try to re-open a substream again.
        /// Use [`Peers::set_peer_notifications_out_desired`] with [`DesiredState::DesiredReset`]
        /// in order to try again.
        result: Result<Vec<u8>, NotificationsOutErr>,
    },

    /// A previously open outbound substream has been closed by the remote. Can only happen after
    /// a corresponding successful [`Event::NotificationsOutResult`] event has been emitted in the
    /// past.
    ///
    /// This combination of [`PeerId`] and notification protocol will now be returned when calling
    /// [`Peers::refused_notifications_out`].
    NotificationsOutClose {
        /// Peer the substream is no longer open with.
        peer_id: PeerId,
        /// Notifications protocol the substream is about.
        notifications_protocol_index: usize,
    },

    /// Received a notification on a notifications substream of a connection.
    NotificationsIn {
        /// Peer that sent the notification.
        peer_id: PeerId,
        /// Notifications protocol the substream is about.
        notifications_protocol_index: usize,
        /// Payload of the notification. Opaque to this state machine.
        ///
        /// > **Note**: Keep in mind that this data is untrusted.
        notification: Vec<u8>,
    },

    /// Remote has closed a previously-open inbound notifications substream.
    NotificationsInClose {
        /// Peer the substream is no longer with.
        peer_id: PeerId,
        /// Notifications protocol the substream is about.
        notifications_protocol_index: usize,
        /// If `Ok`, the substream has been closed gracefully. If `Err`, a problem happened.
        outcome: Result<(), NotificationsInClosedErr>,
    },
}

/// See [`Peers::set_peer_notifications_out_desired`].
#[derive(Debug, Copy, Clone, PartialEq, Eq)]
pub enum DesiredState {
    /// Substream is no longer desired. Close any existing substream.
    NotDesired,
    /// Substream is now desired. If the state was already "desired" and the peer has refused this
    /// substream in the past, do nothing.
    Desired,
    /// Substream is now desired. If the peer has refused this substream in the past, try to open
    /// one again.
    DesiredReset,
}

/// Error potentially returned by [`Peers::in_notification_accept`].
#[derive(Debug, derive_more::Display)]
pub enum InNotificationAcceptError {
    /// The request is now obsolete, either because the connection has been shut down or the
    /// remote has canceled their request.
    Obsolete,
}

/// Error potentially returned by [`Peers::queue_notification`].
#[derive(Debug, derive_more::Display)]
pub enum QueueNotificationError {
    /// Queue of notifications with that peer is full.
    QueueFull,
}
