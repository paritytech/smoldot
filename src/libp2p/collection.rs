// Smoldot
// Copyright (C) 2019-2022  Parity Technologies (UK) Ltd.
// SPDX-License-Identifier: GPL-3.0-or-later WITH Classpath-exception-2.0

// This program is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.

// This program is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.

// You should have received a copy of the GNU General Public License
// along with this program.  If not, see <http://www.gnu.org/licenses/>.

//! Collection of libp2p connections.
//!
//! The [`Network`] struct in this module is a collection of libp2p connections. In the
//! documentation below, it is also called the *coordinator*.
//!
//! When a connection is inserted in the collection with [`Network::insert_single_stream`] or
//! [`Network::insert_multi_stream`], two objects are returned: an identifier for this new
//! connection assigned by the collection, and a [`SingleStreamConnectionTask`] or
//! [`MultiStreamConnectionTask`].
//!
//! All the [`SingleStreamConnectionTask`]s/[`MultiStreamConnectionTask`] created by the
//! [`Network`] communicate with that [`Network`] by passing messages. Passing the messages has
//! to be done explicitly by the API user. It is the responsibility of the API user to pull
//! messages from the coordinator (i.e. the [`Network`]) and push them onto the
//! [`SingleStreamConnectionTask`] or [`MultiStreamConnectionTask`] and vice-versa.
//!
//! # Usage
//!
//! - Whenever a new connection is established, use  [`Network::insert_single_stream`] or
//! [`Network::insert_multi_stream`] to allocate a connection in the collection.
//! - When a connection has received data or is ready to send more data, use
//! [`SingleStreamConnectionTask::read_write`], [`SingleStreamConnectionTask::reset`],
//! [`MultiStreamConnectionTask::substream_read_write`], [`MultiStreamConnectionTask::reset`],
//! [`MultiStreamConnectionTask::add_substream`], and/or
//! [`MultiStreamConnectionTask::desired_outbound_substreams`] to synchronize the state of the
//! task with the actual state of the connection.
//! - Pull messages from the [`SingleStreamConnectionTask`]s and [`MultiStreamConnectionTask`]s
//! and inject them into the [`Network`], and vice versa.
//! - In parallel, continuously call [`Network::next_event`] to process the events generated by
//! the calls to [`Network::inject_connection_message`].
//!

use super::connection::{established, handshake, NoiseKey};
use alloc::{
    collections::{BTreeMap, BTreeSet, VecDeque},
    string::String,
    sync::Arc,
    vec::Vec,
};
use core::{
    hash::Hash,
    ops::{self, Add, Sub},
    time::Duration,
};
use rand::Rng as _;
use rand_chacha::{rand_core::SeedableRng as _, ChaCha20Rng};

pub use super::peer_id::PeerId;
pub use super::read_write::ReadWrite;
pub use established::{ConfigRequestResponse, ConfigRequestResponseIn, InboundError};
pub use handshake::HandshakeError;

pub use multi_stream::MultiStreamConnectionTask;
pub use single_stream::SingleStreamConnectionTask;

mod multi_stream;
mod single_stream;

/// Configuration for a [`Network`].
pub struct Config {
    /// Seed for the randomness within the networking state machine.
    pub randomness_seed: [u8; 32],

    /// Number of connections containers should initially allocate for.
    pub capacity: usize,

    pub notification_protocols: Vec<NotificationProtocolConfig>,

    pub request_response_protocols: Vec<ConfigRequestResponse>,

    /// Amount of time after which a connection handshake is considered to have taken too long
    /// and must be aborted.
    pub handshake_timeout: Duration,

    /// Name of the ping protocol on the network.
    pub ping_protocol: String,

    /// Key used for the encryption layer.
    /// This is a Noise static key, according to the Noise specification.
    /// Signed using the actual libp2p key.
    pub noise_key: NoiseKey,
}

/// Configuration for a specific overlay network.
///
/// See [`Config::notification_protocols`].
pub struct NotificationProtocolConfig {
    /// Name of the protocol negotiated on the wire.
    pub protocol_name: String,

    /// Optional alternative names for this protocol. Can represent different versions.
    ///
    /// Negotiated in order in which they are passed.
    // TODO: presently unused
    pub fallback_protocol_names: Vec<String>,

    /// Maximum size, in bytes, of the handshake that can be received.
    pub max_handshake_size: usize,

    /// Maximum size, in bytes, of a notification that can be received.
    pub max_notification_size: usize,
}

/// Identifier of a connection spawned by the [`Network`].
//
// Identifiers are never reused.
#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct ConnectionId(u64);

impl ConnectionId {
    /// Returns the value that compares inferior or equal to any possible [`ConnectionId`̀].
    pub fn min_value() -> Self {
        ConnectionId(u64::min_value())
    }

    /// Returns the value that compares superior or equal to any possible [`ConnectionId`̀].
    pub fn max_value() -> Self {
        ConnectionId(u64::max_value())
    }
}

/// Identifier of a request, or an inbound substream, or an outbound substream.
//
// Identifiers are never reused.
#[derive(Debug, Copy, Clone, PartialEq, Eq, PartialOrd, Ord, Hash)]
pub struct SubstreamId(u64);

impl SubstreamId {
    /// Returns the value that compares inferior or equal to any possible [`SubstreamId`̀].
    pub fn min_value() -> Self {
        SubstreamId(u64::min_value())
    }

    /// Returns the value that compares superior or equal to any possible [`SubstreamId`̀].
    pub fn max_value() -> Self {
        SubstreamId(u64::max_value())
    }
}

/// Data structure containing the list of all connections, pending or not, and their latest known
/// state. See also [the module-level documentation](..).
pub struct Network<TConn, TNow> {
    /// Messages waiting to be sent to connection tasks.
    messages_to_connections: VecDeque<(ConnectionId, CoordinatorToConnectionInner<TNow>)>,

    /// Messages received from connection tasks. Processed in [`Network::next_event`].
    pending_incoming_messages: VecDeque<(ConnectionId, ConnectionToCoordinatorInner)>,

    /// Id to assign to the next connection.
    next_connection_id: ConnectionId,

    /// Id to assign to the next substream, such as the next request or next notifications
    /// substream.
    ///
    /// All substreams share the same pool of ids across all connections.
    next_substream_id: SubstreamId,

    /// List of all connections in the data structure.
    connections: hashbrown::HashMap<ConnectionId, Connection<TConn>, fnv::FnvBuildHasher>,

    /// If `Some`, the given connection is in the process of shutting down. Calling
    /// [`Network::next_event`] will cancel all ongoing requests and notification substreams
    /// that concern this connection before processing any other incoming message.
    shutting_down_connection: Option<ConnectionId>,

    /// List of all outgoing notification substreams that we have opened. Can be either pending
    /// (waiting for the connection task to say whether it has been accepted or not) or fully
    /// open.
    outgoing_notification_substreams:
        hashbrown::HashMap<SubstreamId, (ConnectionId, SubstreamState), fnv::FnvBuildHasher>,

    /// Always contains the same entries as [`Network::outgoing_notification_substreams`] but
    /// ordered differently.
    outgoing_notification_substreams_by_connection: BTreeSet<(ConnectionId, SubstreamId)>,

    /// List of all requests that have been started locally.
    outgoing_requests: BTreeSet<(ConnectionId, SubstreamId)>,

    /// List in incoming notification substreams that connections have received. Can be either
    /// pending (waiting to be accepted/refused) or fully opened.
    ///
    /// The substream ID of the substream is allocated by the connection task, and thus we need
    /// to keep a mapping of inner `<->` substream IDs.
    ingoing_notification_substreams: hashbrown::HashMap<
        SubstreamId,
        (ConnectionId, SubstreamState, established::SubstreamId),
        fnv::FnvBuildHasher,
    >,

    /// Always contains the same entries as [`Network::ingoing_notification_substreams`] but
    /// ordered differently.
    ingoing_notification_substreams_by_connection:
        BTreeMap<(ConnectionId, established::SubstreamId), SubstreamId>,

    /// List of requests that connections have received and haven't been answered by the API user
    /// yet.
    ingoing_requests: hashbrown::HashMap<
        SubstreamId,
        (ConnectionId, established::SubstreamId),
        fnv::FnvBuildHasher,
    >,

    /// Always contains the same entries as [`Network::ingoing_requests`] but ordered differently.
    ingoing_requests_by_connection: BTreeSet<(ConnectionId, SubstreamId)>,

    /// Generator for randomness seeds given to the established connections.
    randomness_seeds: ChaCha20Rng,

    /// See [`Config::handshake_timeout`].
    handshake_timeout: Duration,

    /// See [`Config::noise_key`].
    noise_key: Arc<NoiseKey>,

    /// See [`OverlayNetwork`].
    notification_protocols: Arc<[OverlayNetwork]>,

    /// See [`Config::request_response_protocols`].
    request_response_protocols: Arc<[ConfigRequestResponse]>,

    /// See [`Config::ping_protocol`].
    ping_protocol: Arc<str>,
}

struct Connection<TConn> {
    state: InnerConnectionState,

    user_data: TConn,
}

enum InnerConnectionState {
    /// The connection is still in its handshaking state.
    Handshaking,
    /// The connection is fully established.
    Established,
    /// The connection is in the process of shutting down.
    ShuttingDown {
        /// `true` if the state before the shutdown was [`InnerConnectionState::Established`].
        was_established: bool,

        /// `true` if [`Network::start_shutdown`] has been called on this connection.
        ///
        /// Even if the remote starts the shutdown at the same time, from an API perspective if
        /// this flag is `true` it will be considered as if the API user had initiated the
        /// shutdown.
        api_initiated: bool,
    },
}

/// State of a specific overlay network.
///
/// This struct is a slight variation to [`NotificationProtocolConfig`].
struct OverlayNetwork {
    /// See [`NotificationProtocolConfig`].
    config: NotificationProtocolConfig,
}

/// See [`Network::outgoing_notification_substreams`] and
/// [`Network::ingoing_notification_substreams`].
///
/// > **Note**: There is no `Closed` variant, as this corresponds to a lack of entry in the map.
#[derive(Debug, Copy, Clone, PartialEq, Eq, Ord, PartialOrd, Hash)]
enum SubstreamState {
    /// Substream hasn't been accepted or refused yet.
    Pending,
    Open,
}

impl<TConn, TNow> Network<TConn, TNow>
where
    TNow: Clone + Add<Duration, Output = TNow> + Sub<TNow, Output = Duration> + Ord,
{
    /// Initializes a new network data structure.
    pub fn new(config: Config) -> Self {
        let notification_protocols = config
            .notification_protocols
            .into_iter()
            .map(|config| OverlayNetwork { config })
            .collect::<Arc<[_]>>();

        // The initial capacities given to the containers below are more or less arbitrary, the
        // objective being to avoid rellocating the containers.
        Network {
            messages_to_connections: VecDeque::with_capacity(config.capacity * 2),
            pending_incoming_messages: VecDeque::with_capacity(config.capacity * 2),
            next_substream_id: SubstreamId(0),
            handshake_timeout: config.handshake_timeout,
            next_connection_id: ConnectionId(0),
            connections: hashbrown::HashMap::with_capacity_and_hasher(
                config.capacity,
                Default::default(),
            ),
            shutting_down_connection: None,
            outgoing_requests: BTreeSet::new(),
            ingoing_requests: hashbrown::HashMap::with_capacity_and_hasher(
                config.request_response_protocols.len() * config.capacity,
                Default::default(),
            ),
            ingoing_requests_by_connection: BTreeSet::new(),
            outgoing_notification_substreams: hashbrown::HashMap::with_capacity_and_hasher(
                notification_protocols.len() * config.capacity,
                Default::default(),
            ),
            outgoing_notification_substreams_by_connection: BTreeSet::new(),
            ingoing_notification_substreams: hashbrown::HashMap::with_capacity_and_hasher(
                notification_protocols.len() * config.capacity,
                Default::default(),
            ),
            ingoing_notification_substreams_by_connection: BTreeMap::new(),
            randomness_seeds: ChaCha20Rng::from_seed(config.randomness_seed),
            noise_key: Arc::new(config.noise_key),
            notification_protocols,
            request_response_protocols: config.request_response_protocols.into_iter().collect(), // TODO: stupid overhead
            ping_protocol: config.ping_protocol.into(),
        }
    }

    /// Adds a new single-stream connection to the collection.
    ///
    /// Must be passed the moment (as a `TNow`) when the connection as been established, in order
    /// to determine when the handshake timeout expires.
    ///
    /// `is_initiator` must be `true` if the connection has been initiated locally, or `false` if
    /// it has been initiated by the remote.
    pub fn insert_single_stream(
        &mut self,
        when_connected: TNow,
        is_initiator: bool,
        user_data: TConn,
    ) -> (ConnectionId, SingleStreamConnectionTask<TNow>) {
        let connection_id = self.next_connection_id;
        self.next_connection_id.0 += 1;

        let connection_task = SingleStreamConnectionTask::new(
            self.randomness_seeds.gen(),
            is_initiator,
            when_connected + self.handshake_timeout,
            self.noise_key.clone(),
            self.notification_protocols.clone(),
            self.request_response_protocols.clone(),
            self.ping_protocol.clone(),
        );

        let _previous_value = self.connections.insert(
            connection_id,
            Connection {
                state: InnerConnectionState::Handshaking,
                user_data,
            },
        );
        debug_assert!(_previous_value.is_none());

        (connection_id, connection_task)
    }

    /// Adds a new multi-stream connection to the collection.
    pub fn insert_multi_stream<TSubId>(
        &mut self,
        now: TNow,
        user_data: TConn,
    ) -> (ConnectionId, MultiStreamConnectionTask<TNow, TSubId>)
    where
        TSubId: Clone + PartialEq + Eq + Hash,
    {
        let connection_id = self.next_connection_id;
        self.next_connection_id.0 += 1;

        let connection_task = MultiStreamConnectionTask::new(
            self.randomness_seeds.gen(),
            now,
            self.notification_protocols.clone(),
            self.request_response_protocols.clone(),
            self.ping_protocol.clone(),
        );

        let _previous_value = self.connections.insert(
            connection_id,
            Connection {
                state: InnerConnectionState::Handshaking,
                user_data,
            },
        );
        debug_assert!(_previous_value.is_none());

        (connection_id, connection_task)
    }

    /// Switches the connection to a state where it will shut down soon.
    ///
    /// Calling this function does **not** generate a [`Event::StartShutdown`] event for this
    /// connection. The event is implied.
    ///
    /// It is no longer possible to start requests, open notifications substreams, or send
    /// notifications. No new incoming requests or notification substreams will be reported. The
    /// incoming notifications that were sent by the remote before the shutdown started will still
    /// be reported.
    ///
    /// It is possible to call this method on connection that are still in their handshaking
    /// phase.
    ///
    /// This function generates a message destined to the connection. Use
    /// [`Network::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Panic
    ///
    /// Panics if the connection is already shutting down, either because
    /// [`Network::start_shutdown`] was called or a [`Event::StartShutdown`] event was yielded.
    ///
    #[track_caller]
    pub fn start_shutdown(&mut self, connection_id: ConnectionId) {
        let connection = match self.connections.get_mut(&connection_id) {
            Some(c) => c,
            None => panic!(),
        };

        let is_established = match connection.state {
            InnerConnectionState::Handshaking => false,
            InnerConnectionState::Established => true,
            InnerConnectionState::ShuttingDown {
                api_initiated: true,
                ..
            } => panic!("start_shutdown called twice on same connection"), // Forbidden.
            InnerConnectionState::ShuttingDown {
                api_initiated: false,
                ..
            } => panic!("start_shutdown called after StartShutdown event"), // Forbidden.
        };

        connection.state = InnerConnectionState::ShuttingDown {
            was_established: is_established,
            api_initiated: true,
        };

        self.messages_to_connections
            .push_back((connection_id, CoordinatorToConnectionInner::StartShutdown));
    }

    /// Returns true if the collection doesn't contain any connection.
    pub fn is_empty(&self) -> bool {
        self.connections.is_empty()
    }

    /// Returns the number of connections in the collection.
    pub fn len(&self) -> usize {
        self.connections.len()
    }

    /// Returns the state of the given connection.
    ///
    /// # Panic
    ///
    /// Panics if the identifier is invalid or corresponds to a connection that has already
    /// entirely shut down.
    ///
    pub fn connection_state(&self, connection_id: ConnectionId) -> ConnectionState {
        let connection = self.connections.get(&connection_id).unwrap();
        match connection.state {
            InnerConnectionState::Handshaking => ConnectionState {
                established: false,
                shutting_down: false,
            },
            InnerConnectionState::Established => ConnectionState {
                established: true,
                shutting_down: false,
            },
            InnerConnectionState::ShuttingDown {
                was_established, ..
            } => ConnectionState {
                established: was_established,
                shutting_down: true,
            },
        }
    }

    /// Returns the Noise key originally passed as [`Config::noise_key`].
    pub fn noise_key(&self) -> &NoiseKey {
        &self.noise_key
    }

    /// Returns the list the overlay networks originally passed as
    /// [`Config::notification_protocols`].
    pub fn notification_protocols(
        &self,
    ) -> impl ExactSizeIterator<Item = &NotificationProtocolConfig> {
        self.notification_protocols.iter().map(|v| &v.config)
    }

    /// Returns the list the request-response protocols originally passed as
    /// [`Config::request_response_protocols`].
    pub fn request_response_protocols(
        &self,
    ) -> impl ExactSizeIterator<Item = &ConfigRequestResponse> {
        self.request_response_protocols.iter()
    }

    /// Sends a request to the given peer.
    ///
    /// A [`Event::Response`] event will later be generated containing the result of the request.
    /// This event is generated even if the connection the request was sent on has been closed.
    ///
    /// It is invalid to start a request on a connection before a [`Event::HandshakeFinished`]
    /// or after a [`Event::StartShutdown`] has been generated, or after
    /// [`Network::start_shutdown`] has been called.
    ///
    /// Returns a newly-allocated identifier for this substream.
    ///
    /// This function generates a message destined to the connection. Use
    /// [`Network::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Requests
    ///
    /// A request consists in:
    ///
    /// - Opening a substream on an established connection with the target.
    /// - Negotiating the requested protocol (`protocol_index`) on this substream using the
    ///   *multistream-select* protocol.
    /// - Sending the request (`request_data` parameter), prefixed with its length.
    /// - Waiting for the response (prefixed with its length), which is then returned.
    ///
    /// An error happens if the connection closes while the request is in progress, if the remote
    /// doesn't support the given protocol, if the request or response doesn't respect the protocol
    /// limits (see [`ConfigRequestResponse`]), or if the remote takes too much time to answer.
    ///
    /// The timeout is the time between the moment the substream is opened and the moment the
    /// response is sent back. If the emitter doesn't send the request or if the receiver doesn't
    /// answer during this time window, the request is considered failed.
    ///
    /// # Panic
    ///
    /// Panics if `protocol_index` isn't a valid index in [`Config::request_response_protocols`].
    /// Panics if the [`ConnectionId`] is invalid or is a connection that hasn't finished its
    /// handshake or is shutting down.
    ///
    #[track_caller]
    pub fn start_request(
        &mut self,
        target: ConnectionId,
        protocol_index: usize,
        request_data: impl Into<Vec<u8>>,
        timeout: TNow,
    ) -> SubstreamId {
        let connection = match self.connections.get(&target) {
            Some(c) => c,
            None => panic!(),
        };
        assert!(matches!(
            connection.state,
            InnerConnectionState::Established
        ));

        assert!(self
            .request_response_protocols
            .get(protocol_index)
            .is_some());

        let substream_id = self.next_substream_id;
        self.next_substream_id.0 += 1;

        let _was_inserted = self.outgoing_requests.insert((target, substream_id));
        debug_assert!(_was_inserted);

        self.messages_to_connections.push_back((
            target,
            CoordinatorToConnectionInner::StartRequest {
                protocol_index,
                request_data: request_data.into(),
                timeout,
                substream_id,
            },
        ));

        substream_id
    }

    /// Start opening a notifications substream.
    ///
    /// It is invalid to open a notifications substream on a connection before a
    /// [`Event::HandshakeFinished`] or after a [`Event::StartShutdown`] has been generated, or
    /// after [`Network::start_shutdown`] has been called.
    ///
    /// Returns a newly-allocated identifier for this substream.
    ///
    /// This function generates a message destined to the connection. Use
    /// [`Network::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Panic
    ///
    /// Panics if `overlay_network_index` isn't a valid index in [`Config::notification_protocols`].
    /// Panics if the [`ConnectionId`] is invalid or is a connection that hasn't finished its
    /// handshake or is shutting down.
    ///
    #[track_caller]
    pub fn open_out_notifications(
        &mut self,
        connection_id: ConnectionId,
        overlay_network_index: usize,
        now: TNow,
        handshake: impl Into<Vec<u8>>,
    ) -> SubstreamId {
        let connection = match self.connections.get(&connection_id) {
            Some(c) => c,
            None => panic!(),
        };
        assert!(matches!(
            connection.state,
            InnerConnectionState::Established
        ));

        assert!(self
            .notification_protocols
            .get(overlay_network_index)
            .is_some());

        let substream_id = self.next_substream_id;
        self.next_substream_id.0 += 1;

        let _prev_value = self
            .outgoing_notification_substreams
            .insert(substream_id, (connection_id, SubstreamState::Pending));
        debug_assert!(_prev_value.is_none());
        let _was_inserted = self
            .outgoing_notification_substreams_by_connection
            .insert((connection_id, substream_id));
        debug_assert!(_was_inserted);

        self.messages_to_connections.push_back((
            connection_id,
            CoordinatorToConnectionInner::OpenOutNotifications {
                handshake: handshake.into(),
                now,
                overlay_network_index,
                substream_id,
            },
        ));

        substream_id
    }

    /// Start closing a previously-open notifications substream, or cancels opening a
    /// notifications substream.
    ///
    /// All the notifications that have been queued remain queued. The substream actually closes
    /// only once the queue is empty.
    ///
    /// Calling this method does *not* emit any event. The [`SubstreamId`] is considered invalid
    /// after this function returns.
    ///
    /// This function generates a message destined to the connection. Use
    /// [`Network::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Panic
    ///
    /// Panics if [`SubstreamId`] doesn't correspond to an outbound notifications substream.
    ///
    #[track_caller]
    pub fn close_out_notifications(&mut self, substream_id: SubstreamId) {
        // Both `Pending` and `Open` states are accepted.
        let (connection_id, _state) =
            match self.outgoing_notification_substreams.remove(&substream_id) {
                Some(s) => s,
                None => panic!(),
            };
        let _was_in = self
            .outgoing_notification_substreams_by_connection
            .remove(&(connection_id, substream_id));
        debug_assert!(_was_in);

        self.messages_to_connections.push_back((
            connection_id,
            CoordinatorToConnectionInner::CloseOutNotifications { substream_id },
        ));
    }

    /// Adds a notification to the queue of notifications to send to the given peer.
    ///
    /// It is invalid to call this on a [`SubstreamId`] before a successful
    /// [`Event::NotificationsOutResult`] has been yielded.
    ///
    /// Each substream maintains a queue of notifications to be sent to the remote. This method
    /// attempts to push a notification to this queue.
    ///
    /// An error is also returned if the queue exceeds a certain size in bytes, for two reasons:
    ///
    /// - Since the content of the queue is transferred at a limited rate, each notification
    /// pushed at the end of the queue will take more time than the previous one to reach the
    /// destination. Once the queue reaches a certain size, the time it would take for
    /// newly-pushed notifications to reach the destination would start being unreasonably large.
    ///
    /// - If the remote deliberately applies back-pressure on the substream, it is undesirable to
    /// increase the memory usage of the local node.
    ///
    /// Similarly, the queue being full is a normal situation and notification protocols should
    /// be designed in such a way that discarding notifications shouldn't have a too negative
    /// impact.
    ///
    /// Regardless of the success of this function, no guarantee exists about the successful
    /// delivery of notifications.
    ///
    /// This function generates a message destined to the connection. Use
    /// [`Network::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Panics
    ///
    /// Panics if [`SubstreamId`] is not a fully open outbound notifications substream.
    ///
    #[track_caller]
    pub fn queue_notification(
        &mut self,
        substream_id: SubstreamId,
        notification: impl Into<Vec<u8>>,
    ) -> Result<(), QueueNotificationError> {
        let (connection_id, state) = match self.outgoing_notification_substreams.get(&substream_id)
        {
            Some(s) => s,
            None => panic!(),
        };
        assert!(matches!(state, SubstreamState::Open));

        //  TODO: add some back-pressure system and return a `QueueNotificationError` if full

        self.messages_to_connections.push_back((
            *connection_id,
            CoordinatorToConnectionInner::QueueNotification {
                substream_id,
                notification: notification.into(),
            },
        ));

        Ok(())
    }

    /// Accepts a request for an inbound notifications substream reported by an
    /// [`Event::NotificationsInOpen`].
    ///
    /// If a [`Event::NotificationsInClose`] event is yielded, then this function must not be
    /// called and will panic.
    ///
    /// This function generates a message destined to the connection. Use
    /// [`Network::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Panic
    ///
    /// Panics if the [`SubstreamId`] doesn't correspond to an inbound notifications substream.
    ///
    #[track_caller]
    pub fn accept_in_notifications(&mut self, substream_id: SubstreamId, handshake: Vec<u8>) {
        let (connection_id, state, inner_substream_id) =
            match self.ingoing_notification_substreams.get_mut(&substream_id) {
                Some(s) => s,
                None => panic!(),
            };
        assert!(matches!(state, SubstreamState::Pending));

        self.messages_to_connections.push_back((
            *connection_id,
            CoordinatorToConnectionInner::AcceptInNotifications {
                substream_id: *inner_substream_id,
                handshake,
            },
        ));

        *state = SubstreamState::Open;
    }

    /// Rejects a request for an inbound notifications substream reported by an
    /// [`Event::NotificationsInOpen`].
    ///
    /// If a [`Event::NotificationsInClose`] event is yielded, then this function must not be
    /// called and will panic.
    ///
    /// The [`SubstreamId`] is considered no longer valid after this function returns.
    ///
    /// This function generates a message destined to the connection. Use
    /// [`Network::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Panic
    ///
    /// Panics if the [`SubstreamId`] doesn't correspond to an inbound notifications substream.
    ///
    #[track_caller]
    pub fn reject_in_notifications(&mut self, substream_id: SubstreamId) {
        if let Some((connection_id, SubstreamState::Pending, inner_substream_id)) =
            self.ingoing_notification_substreams.remove(&substream_id)
        {
            let _was_in = self
                .ingoing_notification_substreams_by_connection
                .remove(&(connection_id, inner_substream_id));
            debug_assert_eq!(_was_in, Some(substream_id));

            self.messages_to_connections.push_back((
                connection_id,
                CoordinatorToConnectionInner::RejectInNotifications {
                    substream_id: inner_substream_id,
                },
            ));
        } else {
            // Note that, if this is reached, the pending substream is not inserted back
            // in the state machine, meaning that `self` is now in an inconsistent state.
            // But considering that we panic, this state mismatch isn't actually observable.
            panic!()
        }
    }

    /// Responds to an incoming request. Must be called in response to a [`Event::RequestIn`].
    ///
    /// If the substream was in the meanwhile yielded in an [`Event::RequestInCancel`], then this
    /// function must not be called and will panic.
    ///
    /// The [`SubstreamId`] is considered no longer valid after this function returns.
    ///
    /// This function generates a message destined to the connection. Use
    /// [`Network::pull_message_to_connection`] to process these messages after it has returned.
    ///
    /// # Panic
    ///
    /// Panics if the [`SubstreamId`] doesn't correspond to an active incoming request.
    ///
    #[track_caller]
    pub fn respond_in_request(&mut self, substream_id: SubstreamId, response: Result<Vec<u8>, ()>) {
        let (connection_id, inner_substream_id) = match self.ingoing_requests.remove(&substream_id)
        {
            Some(s) => s,
            None => panic!(),
        };

        self.ingoing_requests_by_connection
            .remove(&(connection_id, substream_id));

        self.messages_to_connections.push_back((
            connection_id,
            CoordinatorToConnectionInner::AnswerRequest {
                substream_id: inner_substream_id,
                response,
            },
        ));
    }

    /// Pulls a message that must be sent to a connection.
    ///
    /// The message must be passed to [`SingleStreamConnectionTask::inject_coordinator_message`]
    /// or [`MultiStreamConnectionTask::inject_coordinator_message`] in the appropriate connection.
    ///
    /// This function guarantees that the [`ConnectionId`] always refers to a connection that
    /// is still alive, in the sense that [`SingleStreamConnectionTask::inject_coordinator_message`]
    /// or [`MultiStreamConnectionTask::inject_coordinator_message`] has never returned `None`.
    pub fn pull_message_to_connection(
        &mut self,
    ) -> Option<(ConnectionId, CoordinatorToConnection<TNow>)> {
        self.messages_to_connections
            .pop_front()
            .map(|(id, inner)| (id, CoordinatorToConnection { inner }))
    }

    /// Injects into the state machine a message generated by
    /// [`SingleStreamConnectionTask::pull_message_to_coordinator`] or
    /// [`MultiStreamConnectionTask::pull_message_to_coordinator`].
    ///
    /// This message is queued and is later processed in [`Network::next_event`]. This means that
    /// it is [`Network::next_event`] and not [`Network::inject_connection_message`] that updates
    /// the internals of the state machine according to the content of the message. For example,
    /// if a [`SingleStreamConnectionTask`] sends a message to the coordinator indicating that a
    /// notifications substream has been closed, the coordinator will still believe that it is
    /// open until [`Network::next_event`] processes this message and at the same time returns a
    /// corresponding [`Event`]. Processing messages directly in
    /// [`Network::inject_connection_message`] would introduce "race conditions" where the API
    /// user can't be sure in which state a connection or a substream is.
    pub fn inject_connection_message(
        &mut self,
        connection_id: ConnectionId,
        message: ConnectionToCoordinator,
    ) {
        assert!(self.connections.contains_key(&connection_id));

        // TODO: add a limit for a back-pressure-like system?
        self.pending_incoming_messages
            .push_back((connection_id, message.inner));
    }

    /// Returns the next event produced by the service. Returns `None` if no event is available.
    ///
    /// Call this function in a loop after having injected messages using
    /// [`Network::inject_connection_message`].
    pub fn next_event(&mut self) -> Option<Event<TConn>> {
        loop {
            // When a connection starts its shutdown, its id is put in `shutting_down_connection`.
            // When that happens, we go through the local state and clean up all requests and
            // notification substreams that are in progress/open and return the cancellations
            // as events.
            //
            // `shutting_down_connection` is set back to `None` only if it turns out that there
            // is no request or notification substream in progress/open anymore.
            if let Some(shutting_down_connection) = self.shutting_down_connection {
                // Outgoing notification substreams to close.
                if let Some((_, substream_id)) = self
                    .outgoing_notification_substreams_by_connection
                    .range(
                        (shutting_down_connection, SubstreamId::min_value())
                            ..=(shutting_down_connection, SubstreamId::max_value()),
                    )
                    .cloned()
                    .next()
                {
                    self.outgoing_notification_substreams_by_connection
                        .remove(&(shutting_down_connection, substream_id));
                    let (_, state) = self
                        .outgoing_notification_substreams
                        .remove(&substream_id)
                        .unwrap();
                    return Some(match state {
                        SubstreamState::Open => Event::NotificationsOutReset { substream_id },
                        SubstreamState::Pending => Event::NotificationsOutResult {
                            substream_id,
                            result: Err(NotificationsOutErr::ConnectionShutdown),
                        },
                    });
                }

                // Ingoing notification substreams to close.
                if let Some((key, substream_id)) = self
                    .ingoing_notification_substreams_by_connection
                    .range(
                        (
                            shutting_down_connection,
                            established::SubstreamId::min_value(),
                        )
                            ..=(
                                shutting_down_connection,
                                established::SubstreamId::max_value(),
                            ),
                    )
                    .map(|(k, v)| (*k, *v))
                    .next()
                {
                    self.ingoing_notification_substreams
                        .remove(&substream_id)
                        .unwrap();
                    self.ingoing_notification_substreams_by_connection
                        .remove(&key)
                        .unwrap();

                    return Some(Event::NotificationsInClose {
                        substream_id,
                        outcome: Err(NotificationsInClosedErr::ConnectionShutdown),
                    });
                }

                // Find outgoing requests to cancel.
                if let Some((_, substream_id)) = self
                    .outgoing_requests
                    .range(
                        (shutting_down_connection, SubstreamId::min_value())
                            ..=(shutting_down_connection, SubstreamId::max_value()),
                    )
                    .next()
                {
                    let substream_id = *substream_id;
                    self.outgoing_requests
                        .remove(&(shutting_down_connection, substream_id));

                    return Some(Event::Response {
                        substream_id,
                        response: Err(RequestError::ConnectionShutdown),
                    });
                }

                // Find ingoing requests to cancel.
                if let Some((_, substream_id)) = self
                    .ingoing_requests_by_connection
                    .range(
                        (shutting_down_connection, SubstreamId::min_value())
                            ..=(shutting_down_connection, SubstreamId::max_value()),
                    )
                    .next()
                {
                    let substream_id = *substream_id;

                    let _was_in = self.ingoing_requests.remove(&substream_id);
                    debug_assert!(_was_in.is_some());
                    let _was_in = self
                        .ingoing_requests_by_connection
                        .remove(&(shutting_down_connection, substream_id));
                    debug_assert!(_was_in);

                    return Some(Event::RequestInCancel { substream_id });
                }

                // If this is reached, this connection has no more request or notifications
                // substream that is still in progress or open. The connection is successfully
                // shut down.
                self.shutting_down_connection = None;
            }

            // Now actually process messages.
            let (connection_id, message) = self.pending_incoming_messages.pop_front()?;
            let connection = &mut self.connections.get_mut(&connection_id).unwrap();

            break Some(match message {
                ConnectionToCoordinatorInner::StartShutdown(reason) => {
                    // The `ConnectionToCoordinator` message contains a shutdown reason if
                    // and only if it sends `StartShutdown` as a response to a shutdown
                    // initiated by the remote. If the shutdown was initiated locally
                    // (`api_initiated` is `true`), then it can contain `None`, but it can also
                    // contain `Some` in case the shutdown was initiated by the remote at the same
                    // time as it was initiated locally.

                    let report_event = match &mut connection.state {
                        InnerConnectionState::ShuttingDown {
                            api_initiated: true,
                            ..
                        } => false,
                        InnerConnectionState::ShuttingDown {
                            api_initiated: false,
                            ..
                        } => unreachable!(),
                        st @ InnerConnectionState::Handshaking => {
                            *st = InnerConnectionState::ShuttingDown {
                                api_initiated: false,
                                was_established: false,
                            };
                            true
                        }
                        st @ InnerConnectionState::Established => {
                            *st = InnerConnectionState::ShuttingDown {
                                api_initiated: false,
                                was_established: true,
                            };
                            true
                        }
                    };

                    // Control flow can't reach here if `shutting_down_connection` is ̀`Some`.
                    debug_assert!(self.shutting_down_connection.is_none());
                    self.shutting_down_connection = Some(connection_id);

                    if !report_event {
                        // No `StartShutdown` event is generated if the API user has started
                        // the shutdown themselves. In that case, `StartShutdown` is merely a
                        // confirmation.
                        continue;
                    } else {
                        Event::StartShutdown {
                            id: connection_id,
                            reason: reason.unwrap(), // See comment above.
                        }
                    }
                }
                ConnectionToCoordinatorInner::ShutdownFinished => {
                    let was_established = match &connection.state {
                        InnerConnectionState::ShuttingDown {
                            was_established, ..
                        } => *was_established,
                        _ => unreachable!(),
                    };

                    let user_data = self.connections.remove(&connection_id).unwrap().user_data;
                    self.messages_to_connections.push_back((
                        connection_id,
                        CoordinatorToConnectionInner::ShutdownFinishedAck,
                    ));
                    Event::Shutdown {
                        id: connection_id,
                        was_established,
                        user_data,
                    }
                }
                ConnectionToCoordinatorInner::HandshakeFinished(peer_id) => {
                    debug_assert_eq!(
                        self.ingoing_notification_substreams_by_connection
                            .range(
                                (connection_id, established::SubstreamId::min_value())
                                    ..=(connection_id, established::SubstreamId::max_value())
                            )
                            .count(),
                        0
                    );
                    debug_assert_eq!(
                        self.outgoing_notification_substreams_by_connection
                            .range(
                                (connection_id, SubstreamId::min_value())
                                    ..=(connection_id, SubstreamId::max_value())
                            )
                            .count(),
                        0
                    );
                    debug_assert_eq!(
                        self.ingoing_requests_by_connection
                            .range(
                                (connection_id, SubstreamId::min_value())
                                    ..=(connection_id, SubstreamId::max_value())
                            )
                            .count(),
                        0
                    );

                    match &mut connection.state {
                        InnerConnectionState::ShuttingDown {
                            was_established,
                            api_initiated,
                        } => {
                            debug_assert!(!*was_established);
                            debug_assert!(*api_initiated);
                            continue;
                        }
                        st @ InnerConnectionState::Handshaking => {
                            *st = InnerConnectionState::Established
                        }
                        InnerConnectionState::Established => unreachable!(),
                    }

                    Event::HandshakeFinished {
                        id: connection_id,
                        peer_id,
                    }
                }
                ConnectionToCoordinatorInner::InboundError(error) => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    Event::InboundError {
                        id: connection_id,
                        error,
                    }
                }
                ConnectionToCoordinatorInner::RequestIn {
                    id: connection_substream_id,
                    protocol_index,
                    request,
                } => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    let substream_id = self.next_substream_id;
                    self.next_substream_id.0 += 1;

                    self.ingoing_requests
                        .insert(substream_id, (connection_id, connection_substream_id));
                    self.ingoing_requests_by_connection
                        .insert((connection_id, substream_id));

                    Event::RequestIn {
                        id: connection_id,
                        substream_id,
                        protocol_index,
                        request_payload: request,
                    }
                }
                ConnectionToCoordinatorInner::Response {
                    id: substream_id,
                    response,
                    ..
                } => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    let _was_in = self
                        .outgoing_requests
                        .remove(&(connection_id, substream_id));
                    debug_assert!(_was_in);

                    Event::Response {
                        substream_id,
                        response: response.map_err(RequestError::Substream),
                    }
                }
                ConnectionToCoordinatorInner::NotificationsInOpen {
                    id: inner_substream_id,
                    protocol_index: overlay_network_index,
                    handshake,
                } => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    let substream_id = self.next_substream_id;
                    self.next_substream_id.0 += 1;

                    self.ingoing_notification_substreams.insert(
                        substream_id,
                        (connection_id, SubstreamState::Pending, inner_substream_id),
                    );
                    self.ingoing_notification_substreams_by_connection
                        .insert((connection_id, inner_substream_id), substream_id);

                    Event::NotificationsInOpen {
                        id: connection_id,
                        substream_id,
                        notifications_protocol_index: overlay_network_index,
                        remote_handshake: handshake,
                    }
                }
                ConnectionToCoordinatorInner::NotificationsInOpenCancel {
                    id: inner_substream_id,
                    ..
                } => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    let substream_id = self
                        .ingoing_notification_substreams_by_connection
                        .remove(&(connection_id, inner_substream_id))
                        .unwrap();
                    let _was_in = self.ingoing_notification_substreams.remove(&substream_id);
                    debug_assert!(_was_in.is_some());

                    Event::NotificationsInClose {
                        substream_id,
                        outcome: Err(NotificationsInClosedErr::Substream(
                            established::NotificationsInClosedErr::SubstreamReset,
                        )),
                    }
                }
                ConnectionToCoordinatorInner::NotificationIn {
                    id: inner_substream_id,
                    notification,
                } => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    let substream_id = *self
                        .ingoing_notification_substreams_by_connection
                        .get(&(connection_id, inner_substream_id))
                        .unwrap();

                    Event::NotificationsIn {
                        substream_id,
                        notification,
                    }
                }
                ConnectionToCoordinatorInner::NotificationsInClose {
                    id: inner_substream_id,
                    outcome,
                    ..
                } => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    let substream_id = self
                        .ingoing_notification_substreams_by_connection
                        .remove(&(connection_id, inner_substream_id))
                        .unwrap();
                    let _was_in = self.ingoing_notification_substreams.remove(&substream_id);
                    debug_assert!(_was_in.is_some());

                    Event::NotificationsInClose {
                        substream_id,
                        outcome: outcome.map_err(NotificationsInClosedErr::Substream),
                    }
                }
                ConnectionToCoordinatorInner::NotificationsOutResult {
                    id: substream_id,
                    result,
                } => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    let mut entry = match self.outgoing_notification_substreams.entry(substream_id)
                    {
                        hashbrown::hash_map::Entry::Occupied(e) => e,
                        hashbrown::hash_map::Entry::Vacant(_) => {
                            // This can be reached if the API user closed the substream while it
                            // was being open.
                            continue;
                        }
                    };

                    debug_assert!(matches!(entry.get_mut().1, SubstreamState::Pending));

                    if result.is_ok() {
                        entry.insert((connection_id, SubstreamState::Open));
                    } else {
                        entry.remove();

                        let _was_removed = self
                            .outgoing_notification_substreams_by_connection
                            .remove(&(connection_id, substream_id));
                        debug_assert!(_was_removed);
                    }

                    Event::NotificationsOutResult {
                        substream_id,
                        result,
                    }
                }
                ConnectionToCoordinatorInner::NotificationsOutCloseDemanded {
                    id: substream_id,
                    ..
                } => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    match self.outgoing_notification_substreams.get(&substream_id) {
                        Some((_connection_id, _substream_state)) => {
                            debug_assert_eq!(*_connection_id, connection_id);
                            debug_assert!(matches!(_substream_state, SubstreamState::Open));
                        }
                        None => {
                            // The substream might already have been destroyed if the user closed
                            // the substream while this message was pending in the queue.
                            continue;
                        }
                    }

                    Event::NotificationsOutCloseDemanded { substream_id }
                }
                ConnectionToCoordinatorInner::NotificationsOutReset { id: substream_id } => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    match self.outgoing_notification_substreams.remove(&substream_id) {
                        Some((_connection_id, _substream_state)) => {
                            debug_assert_eq!(_connection_id, connection_id);
                            debug_assert!(matches!(_substream_state, SubstreamState::Open));
                        }
                        None => {
                            // The substream might already have been destroyed if the user closed
                            // the substream while this message was pending in the queue.
                            continue;
                        }
                    }

                    let _was_removed = self
                        .outgoing_notification_substreams_by_connection
                        .remove(&(connection_id, substream_id));
                    debug_assert!(_was_removed);

                    Event::NotificationsOutReset { substream_id }
                }
                ConnectionToCoordinatorInner::PingOutSuccess => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    Event::PingOutSuccess { id: connection_id }
                }
                ConnectionToCoordinatorInner::PingOutFailed => {
                    // Ignore events if a shutdown has been initiated by the coordinator.
                    if let InnerConnectionState::ShuttingDown { api_initiated, .. } =
                        connection.state
                    {
                        debug_assert!(api_initiated);
                        continue;
                    }

                    Event::PingOutFailed { id: connection_id }
                }
            });
        }
    }
}

impl<TConn, TNow> ops::Index<ConnectionId> for Network<TConn, TNow> {
    type Output = TConn;
    fn index(&self, id: ConnectionId) -> &TConn {
        &self.connections.get(&id).unwrap().user_data
    }
}

impl<TConn, TNow> ops::IndexMut<ConnectionId> for Network<TConn, TNow> {
    fn index_mut(&mut self, id: ConnectionId) -> &mut TConn {
        &mut self.connections.get_mut(&id).unwrap().user_data
    }
}

/// See [`Network::connection_state`].
#[derive(Debug, Copy, Clone, PartialEq, Eq)]
pub struct ConnectionState {
    /// If `true`, the connection has finished its handshaking phase.
    pub established: bool,

    /// If `true`, the connection is shutting down.
    pub shutting_down: bool,
}

/// Message from a connection task destined to the coordinator.
pub struct ConnectionToCoordinator {
    inner: ConnectionToCoordinatorInner,
}

enum ConnectionToCoordinatorInner {
    HandshakeFinished(PeerId),

    /// See the corresponding event in [`established::Event`].
    InboundError(established::InboundError),

    /// See the corresponding event in [`established::Event`].
    RequestIn {
        id: established::SubstreamId,
        protocol_index: usize,
        request: Vec<u8>,
    },

    /// See the corresponding event in [`established::Event`].
    Response {
        response: Result<Vec<u8>, established::RequestError>,
        id: SubstreamId,
    },

    /// See the corresponding event in [`established::Event`].
    NotificationsInOpen {
        id: established::SubstreamId,
        protocol_index: usize,
        handshake: Vec<u8>,
    },
    /// See the corresponding event in [`established::Event`].
    NotificationsInOpenCancel {
        id: established::SubstreamId,
    },
    /// See the corresponding event in [`established::Event`].
    NotificationIn {
        id: established::SubstreamId,
        notification: Vec<u8>,
    },
    /// See the corresponding event in [`established::Event`].
    NotificationsInClose {
        id: established::SubstreamId,
        outcome: Result<(), established::NotificationsInClosedErr>,
    },
    /// See the corresponding event in [`established::Event`].
    NotificationsOutResult {
        id: SubstreamId,
        result: Result<Vec<u8>, NotificationsOutErr>,
    },
    /// See the corresponding event in [`established::Event`].
    NotificationsOutCloseDemanded {
        id: SubstreamId,
    },
    /// See the corresponding event in [`established::Event`].
    NotificationsOutReset {
        id: SubstreamId,
    },
    /// See the corresponding event in [`established::Event`].
    PingOutSuccess,
    /// See the corresponding event in [`established::Event`].
    PingOutFailed,

    /// Sent either in response to [`ConnectionToCoordinatorInner::StartShutdown`] (in which case
    /// the content is `None`) or if the remote has initiated the shutdown (in which case the
    /// content is `Some`). After this, no more [`ConnectionToCoordinatorInner`] will be sent
    /// anymore except for [`ConnectionToCoordinatorInner::ShutdownFinished`].
    StartShutdown(Option<ShutdownCause>),

    /// Shutdown has now finished. Always sent after
    /// [`ConnectionToCoordinatorInner::StartShutdown`]. No message is sent by the connection
    /// task anymore after that.
    ///
    /// Must be confirmed with a [`CoordinatorToConnectionInner::ShutdownFinishedAck`].
    ShutdownFinished,
}

/// Message from the coordinator destined to a connection task.
pub struct CoordinatorToConnection<TNow> {
    inner: CoordinatorToConnectionInner<TNow>,
}

enum CoordinatorToConnectionInner<TNow> {
    /// Connection task must terminate. This is always sent back after a
    /// [`ConnectionToCoordinatorInner::ShutdownFinished`].
    ///
    /// This final message is necessary in order to make sure that the coordinator doesn't
    /// generate messages destined to a connection that isn't alive anymore.
    ShutdownFinishedAck,

    /// Connection must start shutting down if it is not already the case.
    /// Before of concurrency, it is possible for this message to be sent/received *after* a
    /// [`ConnectionToCoordinatorInner::StartShutdown`] has been sent.
    StartShutdown,

    StartRequest {
        protocol_index: usize,
        request_data: Vec<u8>,
        timeout: TNow,
        /// Id of the substream assigned by the coordinator.
        /// This is **not** the same as the actual substream used in the connection.
        substream_id: SubstreamId,
    },
    OpenOutNotifications {
        /// Id of the substream assigned by the coordinator.
        /// This is **not** the same as the actual substream used in the connection.
        substream_id: SubstreamId,
        overlay_network_index: usize,
        now: TNow,
        handshake: Vec<u8>,
    },
    CloseOutNotifications {
        /// Id of the substream assigned by the coordinator.
        /// This is **not** the same as the actual substream used in the connection.
        substream_id: SubstreamId,
    },
    QueueNotification {
        /// Id of the substream assigned by the coordinator.
        /// This is **not** the same as the actual substream used in the connection.
        substream_id: SubstreamId,
        notification: Vec<u8>,
    },
    AcceptInNotifications {
        substream_id: established::SubstreamId,
        handshake: Vec<u8>,
    },
    RejectInNotifications {
        substream_id: established::SubstreamId,
    },

    /// Answer an incoming request.
    ///
    /// Since the API doesn't provide any feedback about whether responses have been successfully
    /// received by the remote, the response should simply be ignored in case the substream is
    /// obsolete. In any case, answering an obsolete request is not an API error because the remote
    /// might have canceled their request while the message containing the response was waiting
    /// in queue.
    AnswerRequest {
        substream_id: established::SubstreamId,
        response: Result<Vec<u8>, ()>,
    },
}

/// Event generated by [`Network::next_event`].
#[derive(Debug)]
pub enum Event<TConn> {
    /// Handshake of the given connection has completed.
    ///
    /// This event can only happen once per connection.
    HandshakeFinished {
        /// Identifier of the connection whose handshake is finished.
        id: ConnectionId,
        /// Identity of the peer on the other side of the connection.
        peer_id: PeerId,
    },

    /// A transport-level connection (e.g. a TCP socket) is starting its shutdown.
    ///
    /// It is no longer possible to start requests, open notification substreams, or open
    /// notifications on this connection, and no new incoming requests or notification substreams
    /// will be reported as events.
    ///
    /// Further events will close all existing substreams (requests and notifications) one by one.
    /// Once all substreams have been closed, a [`Event::Shutdown`] is reported.
    ///
    /// Keep in mind that this event can also happen for connections that haven't finished their
    /// handshake.
    ///
    /// This event is **not** generated when [`Network::start_shutdown`] is called.
    StartShutdown {
        /// Identifier of the connection that is starting its shutdown.
        id: ConnectionId,
        /// Reason why the connection is starting its shutdown. Because this event is not generated
        /// when the shutdown is initiated locally, the reason is always cause by the remote.
        reason: ShutdownCause,
    },

    /// A transport-level connection (e.g. a TCP socket) has been shut down.
    ///
    /// This [`ConnectionId`] is no longer valid, and using it will result in panics.
    Shutdown {
        /// Identifier of the connection that has finished its shutdown.
        id: ConnectionId,
        /// `true` if the connection was in its established phase before the shutdown.
        was_established: bool,
        /// User data that was stored in the state machine for this connection.
        user_data: TConn,
    },

    /// Received an incoming substream, but this substream has produced an error.
    ///
    /// > **Note**: This event exists only for diagnostic purposes. No action is expected in
    /// >           return.
    InboundError {
        /// Identifier of the connection that has received the substream.
        id: ConnectionId,
        /// Error that happened.
        error: InboundError,
    },

    /// Outcome of a request started using [`Network::start_request`].
    ///
    /// *All* requests always lead to an outcome, even if the connection has been closed while the
    /// request was in progress.
    Response {
        /// Substream that was returned by [`Network::start_request`].
        substream_id: SubstreamId,
        /// If the request is successful, contains the response sent back by the remote. Otherwise,
        /// contains the reason why the request isn't successful.
        response: Result<Vec<u8>, RequestError>,
    },

    /// Received a request from a request-response protocol.
    RequestIn {
        /// Identifier of the connection that has received the request.
        id: ConnectionId,
        /// Substream on which the request has been received. Must be passed back when providing
        /// the response.
        substream_id: SubstreamId,
        /// Index of the negotiated protocol within [`Config::request_response_protocols`].
        protocol_index: usize,
        /// Payload that has been sent by the remote. Its interpretation is beyond the scope of
        /// this module.
        request_payload: Vec<u8>,
    },

    /// Request received earlier has been canceled by the remote.
    ///
    /// The [`SubstreamId`] is now invalid.
    RequestInCancel { substream_id: SubstreamId },

    /// Outcome of trying to open a substream with [`Network::open_out_notifications`].
    ///
    /// If `Ok`, it is now possible to send notifications on this substream.
    /// If `Err`, the substream no longer exists and the [`SubstreamId`] becomes invalid.
    NotificationsOutResult {
        // TODO: what if fallback?
        substream_id: SubstreamId,
        /// If `Ok`, contains the handshake sent back by the remote. Its interpretation is out of
        /// scope of this module.
        result: Result<Vec<u8>, NotificationsOutErr>,
    },

    /// Remote has closed an outgoing notifications substream, meaning that it demands the closing
    /// of the substream. Use [`Network::close_out_notifications`] as soon as possible, which is
    /// typically after all outbound notifications that need to be queued have been queued.
    ///
    /// This event is only generated for notification substreams that are fully open.
    NotificationsOutCloseDemanded { substream_id: SubstreamId },

    /// A previously open outbound substream has been closed, by the remote or as a consequence of
    /// the connection shutting down.
    ///
    /// This event is only generated for notification substreams that are fully open.
    ///
    /// The substream no longer exists and the [`SubstreamId`] becomes invalid.
    NotificationsOutReset { substream_id: SubstreamId },

    /// The remote would like to open a notifications substream.
    ///
    /// The substream needs to be accepted or refused using [`Network::accept_in_notifications`]
    /// or [`Network::reject_in_notifications`].
    NotificationsInOpen {
        /// Identifier of the connection that has received the notification substream request.
        id: ConnectionId,
        /// Newly-generated identifier for the substream on which the request has been received.
        /// Must be passed back when accepting or refusing the substream.
        substream_id: SubstreamId,
        /// Index of the negotiated protocol within [`Config::notification_protocols`].
        notifications_protocol_index: usize,
        /// Handshake that has been sent by the remote. Its interpretation is beyond the scope of
        /// this module.
        remote_handshake: Vec<u8>,
    },

    /// Received a notification on a notifications substream of a connection.
    NotificationsIn {
        /// Substream on which the notification has been received. Guaranteed to be a substream
        /// that has been accepted with [`Network::accept_in_notifications`].
        substream_id: SubstreamId,
        /// Notification that the remote has sent. The meaning of this data is out of scope of
        /// this module.
        notification: Vec<u8>,
    },

    /// The remote has closed an incoming notifications substream.
    ///
    /// This can happen both before or after the notification substream has been accepted. If it
    /// happens before the substream has been accepted, this event should be interpreted as
    /// canceling the opening.
    NotificationsInClose {
        /// Substream that has been closed. Guaranteed to match a substream that was earlier
        /// reported with a [`Event::NotificationsInOpen`].
        substream_id: SubstreamId,
        /// Reason why the substream has been closed.
        outcome: Result<(), NotificationsInClosedErr>,
    },

    /// An outgoing ping has succeeded. This event is generated automatically over time for each
    /// connection in the collection.
    PingOutSuccess { id: ConnectionId },
    /// An outgoing ping has failed. This event is generated automatically over time for each
    /// connection in the collection.
    PingOutFailed { id: ConnectionId },
}

/// Reason why a connection is shutting down. See [`Event::StartShutdown`].
#[derive(Debug, derive_more::Display)]
pub enum ShutdownCause {
    /// Shutdown was demanded by the remote and performed cleanly.
    CleanShutdown,
    /// Remote has abruptly reset the connection.
    RemoteReset,
    /// Error in the connection protocol of a fully established connection.
    ProtocolError(established::Error),
    /// Error in the protocol of the handshake.
    HandshakeError(HandshakeError),
    /// Handshake phase took too long.
    HandshakeTimeout,
}

#[derive(Debug, derive_more::Display, Clone)]
pub enum RequestError {
    /// Request has been canceled because the connection as a whole is being shut down.
    ConnectionShutdown,

    /// Error happened in the context of the substream.
    #[display(fmt = "{}", _0)]
    Substream(established::RequestError),
}

#[derive(Debug, derive_more::Display, Clone)]
pub enum NotificationsOutErr {
    /// Opening has been interrupted because the connection as a whole is being shut down.
    ConnectionShutdown,

    /// Error happened in the context of the substream.
    #[display(fmt = "{}", _0)]
    Substream(established::NotificationsOutErr),
}

#[derive(Debug, derive_more::Display, Clone)]
pub enum NotificationsInClosedErr {
    /// Substream has been closed because the connection as a whole is being shut down.
    ConnectionShutdown,

    /// Error happened in the context of the substream.
    #[display(fmt = "{}", _0)]
    Substream(established::NotificationsInClosedErr),
}

/// Error potentially returned by [`Network::queue_notification`].
#[derive(Debug, derive_more::Display)]
pub enum QueueNotificationError {
    /// Queue of notifications with that peer is full.
    QueueFull,
}
